[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Atelier du la sphère sondage sur l’estimation de variance",
    "section": "",
    "text": "Calendrier\nDes coquilles peuvent être cachées dans les documents : n’hésitez pas à le notifier par mail ou faire un pull-request.\n\n\n\nDate\nHeure\nSujet\nLien\nDéfinitifs ?\nCompléments / Corrections\n\n\n\n\n20 juin 2024\n13:00 - 15:00\nPrésentation du calcul de variance analytique\n\n❌\n\n\n\n20 juin 2024\n13:00 - 15:00\nApplication avec gustave\n\n❌\n\n\n\n2 juillet 2024\n13:00 - 15:00\nPrésentation du calcul de variance par bootstrap\n\n❌\n\n\n\n\n\n\nEnregistrement au format pdf\nLes présentations sont disponibles au format html. Cependant, ce format n’est pas le plus optimisé pour l’annotation. Il est possible d’enregistrer au format pdf en :\n\nutilisant Google Chrome ou un autre navigateur,\nappuyant sur la touche e de votre clavier lorsque vous êtes sur la présentation,\nappuyant sur la combinaison CTRL + P et en enregistrant au format pdf.\n\n\n\n\nTransformation de html vers pdf"
  },
  {
    "objectID": "presentations/pres_analytique.html#pourquoi",
    "href": "presentations/pres_analytique.html#pourquoi",
    "title": "Atelier du réseau sondage",
    "section": "Pourquoi ?",
    "text": "Pourquoi ?\n\nLa variance permet de quantifier la variabilité d’un estimateur.\nCertaines enquêtes de l’Insee sont soumises à un cadre réglementaire européen, qui leur impose entre autres des niveaux de précision cibles pour quelques indicateurs.\nLe calcul de précision tend, de fait, à prendre une part de plus en plus importante dans la production de statistiques publiques.\nTout calcul de précision doit prendre en compte différents éléments :\n\nLe plan de sondage retenu.\nLe choix de l’estimateur initial.\nLes différentes étapes de redressements : correction de la non-réponse, partage des poids, calage …"
  },
  {
    "objectID": "presentations/pres_analytique.html#intérêt-des-calculs-de-variance",
    "href": "presentations/pres_analytique.html#intérêt-des-calculs-de-variance",
    "title": "Atelier du réseau sondage",
    "section": "Intérêt des calculs de variance",
    "text": "Intérêt des calculs de variance\n\n\nPour le chargé d’études :\n\nPermet la construction d’un intervalle de confiance\nPermet de commenter la significativité des variations d’un indicateur\n\n\n\n\n\nL’estimation de variance permet de mesurer la qualité des indicateurs produits :\n\nUtilisée pour les rapports qualité transmis à Eurostat\nRequise pour divers indicateurs dans différentes enquêtes par le règlement IESS\n\n\n\n\n\nL’estimation de variance gagne en importance dans le processus de production des enquêtes"
  },
  {
    "objectID": "presentations/pres_analytique.html#le-règlement-cadre-iess",
    "href": "presentations/pres_analytique.html#le-règlement-cadre-iess",
    "title": "Atelier du réseau sondage",
    "section": "Le règlement cadre IESS",
    "text": "Le règlement cadre IESS\n\n\nLe règlement-cadre IESS (Integrated European Social Statistics) a été adopté en avril 2019.\nIl vise à imposer un cadre européen harmonisé afin de garantir la comparabilité des indicateurs entre pays des États membres.\nL’Insee a mis en place un programme de rénovation progressive de ses enquêtes sociales, avec une part grandissante sous règlement européen.\n\n\n\n\nContraintes sur les écarts-types d’estimateurs nationaux et régionaux (au niveau des NUTS 2 : anciennes régions pour la France).\n\nLes estimateurs concernés sont toujours des taux.\nLes contraintes de précision dépendent des tailles de population : contraintes moins strictes pour les petites régions (points 6 et 7 de l’annexe II).\n\n\n\n\n\nHormis pour quelques exceptions, l’écart-type estimé des estimateurs ne doit pas excéder \\(\\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{a\\sqrt{N}+b}}\\) où \\(\\widehat{p}\\) est l’estimateur considéré, \\(a\\) et \\(b\\) sont des paramètres fixés par IESS et \\(N\\) est un nombre d’individus ou de ménages liés à l’indicateur.\n\n\n\n\nLes contraintes de précision régionales sont plus contraignantes pour les régions plus peuplées."
  },
  {
    "objectID": "presentations/pres_analytique.html#le-règlement-fribs",
    "href": "presentations/pres_analytique.html#le-règlement-fribs",
    "title": "Atelier du réseau sondage",
    "section": "Le règlement FRIBS",
    "text": "Le règlement FRIBS\n\nIl existe également un règlement-cadre européen sur les statistiques d’entreprises, nommé FRIBS (Framework Regulation Integrating Business Statistics) et adopté en 2019.\nFRIBS remplace dix règlements sectoriels en vigueur jusqu’en 2021.\nIl crée un cadre juridique commun pour les statistiques d’entreprises, réduisant les incohérences entre domaines et les redondances, sans les supprimer totalement.\nFRIBS s’applique pour l’essentiel à partir de l’année de référence 2021."
  },
  {
    "objectID": "presentations/pres_analytique.html#définitions-usuelles-et-notations.",
    "href": "presentations/pres_analytique.html#définitions-usuelles-et-notations.",
    "title": "Atelier du réseau sondage",
    "section": "Définitions usuelles et notations.",
    "text": "Définitions usuelles et notations.\n\nDans cette présentation, on notera :\n\n\\(\\mathcal{U}\\), une population finie de taille \\(N\\),\n\\(p\\), un plan de sondage défini sur \\(\\mathcal{U}\\),\n\\(S\\) un échantillon aléatoire tiré selon le plan \\(p\\).\n\n\n\n\n\\(\\{y_k\\}\\) : une variable d’intérêt,\n\\(\\{x_k\\}\\) : une variable auxiliaire.\n\n\n\nPour l’inférence, il est commode d’introduire :\n\nPour tout individu \\(k \\in \\mathcal{U}, ~ \\pi_k = \\mathbb{P}(k \\in S)\\) \\(\\to\\) probabilité d’inclusion d’ordre 1.\n\nIl s’agit de la probabilité que l’individu \\(k\\) soit dans l’échantillon \\(S\\).\n\nPour tout couple d’individus \\((k,l) \\in \\mathcal{U}^2, ~ \\pi_{kl} = \\mathbb{P}(k \\in S \\cap l \\in S)\\) \\(\\to\\) probabilité d’inclusion d’ordre 2.\n\nIl s’agit de la probabilité que les individus \\(k\\) et \\(l\\) soient conjointement dans l’échantillon \\(S\\)."
  },
  {
    "objectID": "presentations/pres_analytique.html#estimateur-dhorvitz-thompson",
    "href": "presentations/pres_analytique.html#estimateur-dhorvitz-thompson",
    "title": "Atelier du réseau sondage",
    "section": "Estimateur d’Horvitz-Thompson",
    "text": "Estimateur d’Horvitz-Thompson\n\n\nComment estimer le total \\(\\displaystyle t_y = \\sum_{k \\in \\mathcal{U}} y_k\\) en utilisant l’information disponible uniquement sur l’échantillon \\(S\\) ?\n\nL’estimateur \\(\\displaystyle \\hat{t}_{y,\\text{HT}} = \\sum_{k \\in S} \\frac{y_k}{\\pi_k}\\) est appelé estimateur d’Hovitz-Thompson du total.\n\n\n\n\n\nEst-ce un bon estimateur ?\n\n\n\n\nCritère de biais et de variance.\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\nDéfinition 1 (Biais d’un estimateur) Le biais d’un estimateur \\(\\hat{\\theta}\\) d’une fonction d’intérêt \\(\\theta\\) est donné par \\(\\mathbb{B}(\\hat{\\theta}; \\theta) = \\mathbb{E}(\\hat{\\theta}) - \\theta\\).\n\n\n\n\n\n\n\n\n\n\nMise en garde\n\n\n\nDéfinition 2 (Variance) La variance d’un estimateur \\(\\hat \\theta\\) d’une fonction d’intérêt \\(\\theta\\) est donné par \\(\\mathbb{V}(\\hat \\theta) = \\mathbb{E}(\\left(\\hat \\theta  - \\mathbb{E}(\\hat \\theta) \\right)^2)\\).\nLa variance permet de quantifier la variabilité d’un estimateur."
  },
  {
    "objectID": "presentations/pres_analytique.html#arbitrage-biaisvariance",
    "href": "presentations/pres_analytique.html#arbitrage-biaisvariance",
    "title": "Atelier du réseau sondage",
    "section": "Arbitrage biais/variance",
    "text": "Arbitrage biais/variance"
  },
  {
    "objectID": "presentations/pres_analytique.html#estimateur-dhorvitz-thompson-biais-et-variance",
    "href": "presentations/pres_analytique.html#estimateur-dhorvitz-thompson-biais-et-variance",
    "title": "Atelier du réseau sondage",
    "section": "Estimateur d’Horvitz-Thompson : biais et variance",
    "text": "Estimateur d’Horvitz-Thompson : biais et variance\n\n\nSi pour tout \\(k \\in \\mathcal{U},~~ \\pi_k &gt; 0\\) alors \\(\\hat{t}_{y,\\text{HT}}\\) est un estimateur sans biais de \\(t_y\\).\n\n\n\n\nS’il existe un individu \\(j\\) tel que \\(\\pi_j = 0\\), alors il y a un défaut de couverture \\(\\to\\) biais.\n\n\n\n\nQuid de la variance de \\(\\hat{t}_{y,\\text{HT}}\\) ?\n\n\\[\\mathbb{V}(\\hat t_{y,\\text{HT}}) = \\sum_{k \\in \\color{red}{\\mathcal{U}}} \\sum_{l \\in \\color{red}{\\mathcal{U}}} \\frac{y_k}{\\pi_k} \\frac{y_l}{\\pi_l} \\Delta_{kl}\\] où \\(\\Delta_{kl} = \\pi_{kl} - \\pi_k \\pi_l\\)\nProblème : la variance est fonction des valeurs de \\(\\{y_k\\}\\) sur \\(\\color{red}{\\mathcal{U}}\\) mais cette information n’est disponible que sur \\(\\mathcal{S}\\).\nSolution : estimer la variance.\n\n\n\n\n\n\n\n\n\nEstimateur de variance d’Horvitz-Thompson\n\n\n\\[\\hat{\\mathbb{V}}_\\text{HT}(\\hat t_{y,\\text{HT}}) = \\sum_{k \\in \\mathcal{U}} \\sum_{k \\in \\mathcal{U}} \\frac{y_k}{\\pi_k} \\frac{y_l}{\\pi_l} \\Delta_{kl} \\color{red}{\\frac{I_{kl}}{\\pi_{kl}}} \\color{black} = \\sum_{k \\in S} \\sum_{l \\in S} \\frac{y_k}{\\pi_k} \\frac{y_l}{\\pi_l} {\\frac{\\Delta_{kl}}{\\pi_{kl}}} \\]\nPropriétés :\n\nSi pour tout \\((k,l) \\in \\mathcal{U}^2\\), \\(\\pi_{kl} &gt; 0\\), \\(\\hat{\\mathbb{V}}_\\text{HT}(\\hat t_{y,\\text{HT}})\\) est sans biais pour \\(\\mathbb{V}(\\hat t_{y,\\text{HT}})\\)\n\n\n\n\n\n\n\n\n\n\nEstimateur de Sen-Yates-Grundy\n\n\n\\[\\hat{\\mathbb{V}}_\\text{SYG}(\\hat t_{y,\\text{HT}}) =  - \\frac{1}{2} \\sum_{k \\in \\mathcal{S}} \\sum_{l \\in \\mathcal{S} | k \\neq l} \\left(\\frac{y_k}{\\pi_k} - \\frac{y_l}{\\pi_l} \\right)^2 \\frac{\\Delta_{kl}}{\\pi_{kl}}\\]\nPropriétés :\n\nSi pour tout \\((k,l) \\in \\mathcal{U}^2\\), \\(\\pi_{kl} &gt; 0\\) et le plan \\(p\\) est de taille fixe alors \\(\\hat{\\mathbb{V}}_\\text{SYG}(\\hat t_{y,\\text{HT}})\\) est sans biais pour \\(\\mathbb{V}(\\hat t_{y,\\text{HT}})\\).\nSi pour tout \\((k,l) \\in \\mathcal{U}^2\\), \\(\\pi_{kl} - \\pi_k \\pi_l \\leq 0\\) alors \\(\\hat{\\mathbb{V}}_\\text{SYG}(\\hat t_{y,\\text{HT}}) \\geq 0\\)."
  },
  {
    "objectID": "presentations/pres_analytique.html#sec-tclsondage",
    "href": "presentations/pres_analytique.html#sec-tclsondage",
    "title": "Atelier du réseau sondage",
    "section": "Théorème central limite en sondage",
    "text": "Théorème central limite en sondage\n\n\nRappel sur le théorème central limite dans le cas i.i.d : Rappel\nEst-ce que le théorème central limite est applicable en sondage sur l’estimateur d’Horvitz-Thompson ?\nPar exemple : \\[\\frac{1}{\\mathbb{V}^{\\frac{1}{2}}(\\hat t_{y,\\text{HT}})}(\\hat t_{y,\\text{HT}} - t_y) \\hookrightarrow \\mathcal{N}(0,1) \\] où \\(\\hookrightarrow\\) désigne la convergence en loi\n\n\n\n\nUn théorème central limite pour les gouverner tous : ❌\n\nHájek (1960) : pour le SRS.\nBerger (1998) : pour les plans à forte entropie.\nChauvet (2015) : pour les sondages à plusieurs degrés avec un \\(\\text{SASSR}\\) au premier degré. …\n\nChamp de recherche ouvert : théorie unifiée ? D’autres TCL ?"
  },
  {
    "objectID": "presentations/pres_analytique.html#théorème-central-limite-en-sondage",
    "href": "presentations/pres_analytique.html#théorème-central-limite-en-sondage",
    "title": "Atelier du réseau sondage",
    "section": "Théorème central limite en sondage",
    "text": "Théorème central limite en sondage\n\n\nEn général, on supposera toujours que le théorème central limite tient : \\[\\frac{1}{\\mathbb{V}^{\\frac{1}{2}}(\\hat t_{y,\\text{HT}})}(\\hat t_{y,\\text{HT}} - t_y) \\hookrightarrow \\mathcal{N}(0,1) \\]\n\n\n\n\nUn intervalle de confiance asymptotique au niveau \\(1-\\alpha\\) est donné par : \\[ [ \\hat t_{y,\\text{HT}} - q_{1 - \\frac{\\alpha}{2}} \\color{red}{\\mathbb{V}}^{\\frac{1}{2}}(\\hat t_{y,\\text{HT}}), \\hat t_{y,\\text{HT}} + q_{1 - \\frac{\\alpha}{2}} \\color{red}{\\mathbb{V}}^{\\frac{1}{2}}(\\hat t_{y,\\text{HT}})  ] \\] avec \\(q_{1 - \\frac{\\alpha}{2}}\\), le quantile d’ordre \\(1- \\frac{\\alpha}{2}\\) de la loi normale centrée réduite\n\n\n\n\nProblème : \\(\\mathbb{V}(\\hat t_{y,\\text{HT}})\\) pas connu mais … on peut utiliser un estimateur consistant de \\(\\hat{\\mathbb{V}}(\\hat t_{y,\\text{HT}})\\).\n\n\n\n\n\n\nLemme de Slustky\n\n\nSi \\((X_n,Y_n)_{n \\in \\mathbb{N}}\\) tel que \\(X_n \\to^{\\mathbb{P}} c\\) (une constante) et \\(Y_n  \\hookrightarrow Y\\) alors \\((X_n, Y_n) \\hookrightarrow (X,Y)\\).\n\n\n\n\n\n\\(\\to\\) Remplacement de \\(\\mathbb{V}(\\hat t_{y,\\text{HT}})\\) par un estimateur \\(\\hat{\\mathbb{V}}_\\text{HT}(\\hat t_{y,\\text{HT}})\\) ou \\(\\hat{\\mathbb{V}}_\\text{SYG}(\\hat t_{y,\\text{HT}})\\) (si taille fixe)."
  },
  {
    "objectID": "presentations/pres_analytique.html#application-au-plan-aléatoire-simple-sans-remise",
    "href": "presentations/pres_analytique.html#application-au-plan-aléatoire-simple-sans-remise",
    "title": "Atelier du réseau sondage",
    "section": "Application au plan aléatoire simple sans remise",
    "text": "Application au plan aléatoire simple sans remise\n\n\n\nPlan aléatoire simple sans remise\n\n\n\\(p_{\\text{SASSR}(n;N)}\\) est un plan aléatoire simple sans remise de taille \\(n\\) parmi \\(N\\) si :\n\nTous les échantillons de taille \\(n\\) ont la même probabilité d’être tiré,\nSi tous les échantillons de taille différente de \\(n\\) ont une probabilité nulle d’être tiré.\n\nSi \\(S \\sim p_{\\text{SASSR}(n;N)}\\) alors pour tout \\((k,l) \\in \\mathcal{U}^2, ~~ \\pi_k = \\frac{n}{N}\\) et si \\(k \\neq l~~\\), \\(\\pi_{kl} = \\frac{n(n-1)}{N(N-1)}\\)\nApplication : \\(\\hat{\\mathbb{V}}_\\text{SYG}(\\hat t_{y,\\text{HT}}) = \\hat{\\mathbb{V}}_\\text{HT}(\\hat t_{y,\\text{HT}}) = \\frac{N^2}{n} (1 - \\frac{n}{N}) s^2_y\\) où \\(s^2_y\\) est la dispersion de la variable \\(\\{y_k\\}\\) sur l’échantillon \\(S\\).\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/pres_analytique.html#application-au-plan-poissonien",
    "href": "presentations/pres_analytique.html#application-au-plan-poissonien",
    "title": "Atelier du réseau sondage",
    "section": "Application au plan poissonien",
    "text": "Application au plan poissonien\n\n\n\nPlan poissonien\n\n\n\\(p_{\\text{Poisson}(\\textbf{p})}\\) où \\(\\textbf{p} = (p_1, ..., p_N) \\in [0;1]^N\\) est un plan de Poisson si :\n\nTous les individus sont tirés indépendamment les uns des autres,\nLa probabilité d’un individu \\(k\\) soit dans l’échantillon est \\(p_k\\).\n\nSi \\(S \\sim p_{\\text{Poisson}(\\textbf{p})}\\) alors pour tout \\((k,l) \\in \\mathcal{U}^2, ~~ \\pi_k = \\textbf{p}_k\\) et si \\(k \\neq l~~\\), \\(\\pi_{kl} = \\textbf{p}_k \\textbf{p}_l\\)\nApplication : \\(\\displaystyle \\hat{\\mathbb{V}}_\\text{HT}(\\hat t_{y,\\text{HT}}) = \\sum_{k \\in S} y_k^2 \\frac{1-\\textbf{p}_k}{\\textbf{p}_k^2}\\)\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/pres_analytique.html#approximations-classiques",
    "href": "presentations/pres_analytique.html#approximations-classiques",
    "title": "Atelier du réseau sondage",
    "section": "Approximations classiques",
    "text": "Approximations classiques\n\n\nParfois, il est délicat de calculer les probabilités d’inclusion d’ordre 2.\n\n\n\n\nPour certains plans, des approximations sont utilisées.\n\n\n\n\nPour les plans équilibrés à forte entropie : formule de Deville-Tiilé (Deville et Tillé (2000)). \\[\\hat{\\mathbb{V}}_\\text{DT}(\\hat{t}_{y,\\text{HT}}) = \\frac{n}{n-d}\\sum_{k \\in S} (1 - \\pi_k) \\left(\\frac{y_k}{\\pi_k} - \\frac{x_k}{\\pi_k} \\hat{\\beta} \\right)^2\\] où \\(\\hat{\\beta}\\) est le coefficient estimé sur \\(\\mathcal{S}\\) de la régression de \\(\\{\\frac{y_k}{\\pi_k}\\}\\) par \\(\\{\\frac{x_k}{\\pi_k}\\} \\in \\mathbb{R}^d\\) pondérée par \\(1-\\pi_k\\).\n\nRemarque : le plan aléatoire simple sans remise \\(p_{\\text{SASSR}(n;N)}\\) est un plan équilibré sur la variable \\(\\{\\pi_k\\}\\) \\(\\to\\) il est donc possible d’utiliser l’approximation de Deville-Tillé et \\(\\hat{\\mathbb{V}}_\\text{DT}(\\hat{t}_{y,\\text{HT}}) = \\hat{\\mathbb{V}}_\\text{SYG}(\\hat{t}_{y,\\text{HT}}) = \\hat{\\mathbb{V}}_\\text{HT}(\\hat{t}_{y,\\text{HT}})\\)\n\n\n\n\n\nPour le tirage systématique : approximation par la variance sous un plan aléatoire simple."
  },
  {
    "objectID": "presentations/pres_analytique.html#section",
    "href": "presentations/pres_analytique.html#section",
    "title": "Atelier du réseau sondage",
    "section": "",
    "text": "Plan de l’enquête Histoire de Vie et Patrimoine\n\n\n\nIdée 1\n\n: utiliser les résultats présentés. ❌\n\n\n\n\n\nProblème 1\n\n: le calcul des probabilités d’inclusion d’ordre deux est (très) délicat.\n\n\n\n\n\nIdée 2\n\n: estimer les probabilités d’inclusion d’ordre deux par simulation. ❌\n\n\n\n\n\nProblème 2\n\n: l’estimation des probabilités d’inclusion d’ordre deux est très gourmande en ressource informatique et peut conduire à des estimations instables.\n\n\n\n\n\nIdée 3\n\n: décomposer le calcul de l’estimateur de la variance degré par degré. ✅\n\n\n\n\n\nIdée 4\n\n: utiliser des méthodes de réplication. ✅"
  },
  {
    "objectID": "presentations/pres_analytique.html#estimation-de-variance-pour-des-plans-à-plusieurs-degrés-rao75",
    "href": "presentations/pres_analytique.html#estimation-de-variance-pour-des-plans-à-plusieurs-degrés-rao75",
    "title": "Atelier du réseau sondage",
    "section": "Estimation de variance pour des plans à plusieurs degrés (Rao (1975))",
    "text": "Estimation de variance pour des plans à plusieurs degrés (Rao (1975))\nSoit \\(p\\) un plan de sondage à deux degrés où \\(p_1\\) désigne le plan de sondage des unités primaires et \\(p_{2|1}\\) le plan de sondage des unités secondaires conditionnellement aux unités primaires. On notera respectivement \\(s_\\text{UP}\\) et \\(s_\\text{US}\\), les échantillons d’unités primaires et secondaires obtenus.\nOn note :\n\n\\(\\pi_u^{(1)}\\), les probabilités d’inclusion d’ordre 1 d’une unité primaire \\(u \\in U_\\text{UP}\\).\n\\(\\pi_l^{(2|1)}\\), les probabilités d’inclusion d’ordre 1 d’une unité secondaire \\(l \\in U_\\text{UP}\\) conditionnellement à l’échantillon des UP.\n\\(\\pi_l^{(1,2)}\\), les probabilités d’inclusion d’ordre 1 d’une unité secondaire \\(l \\in U_\\text{UP}\\).\n\nSoit \\(\\hat{t}_{y,\\text{HT}}\\), l’estimateur d’Horvitz-Thompson d’une variable d’intérêt \\(\\{y_k\\}\\) : \\[\\hat{t}_{y,\\text{HT}} = \\sum_{k \\in S_{\\text{US}}} \\frac{y_k}{\\pi_k^{(1,2)}} = \\sum_{u \\in S_\\text{UP}} \\frac{\\hat{t}_{y,\\text{HT},u}}{\\pi_u^{(1)}} \\text{  avec  } \\hat{t}_{y,\\text{HT},u} = \\sum_{k \\in u \\cap S_\\text{US}} \\frac{y_k}{\\pi_k^{(2|1)}}\\]"
  },
  {
    "objectID": "presentations/pres_analytique.html#section-2",
    "href": "presentations/pres_analytique.html#section-2",
    "title": "Atelier du réseau sondage",
    "section": "",
    "text": "Supposons que :\n\n\nle tirage des unités secondaires au sein des unités primaires sont indépendants d’une unité primaire à l’autre.\n\n\n\n\nl’existence d’un estimateur \\(\\hat{\\mathbb{V}^{1}}(\\hat{t}_{y,\\text{HT}})\\) sans biais de la variance lié au premier degré d’échantillonnage \\(\\mathbb{V}^{1}(\\hat{t}_{y,\\text{HT}})\\) pouvant s’écrire sous la forme \\(\\displaystyle \\hat{\\mathbb{V}} (\\hat{t}_{y,\\text{HT}}) = Q(t_{y_{(1)}}, ..., t_{y_{(n_\\text{UP})}}) = \\sum_{i} \\sum_{j \\neq i} q_{ij} t_{y_{(i)}} t_{y_{(j)}} + \\sum_{i} q_{i} t_{y_{(i)}}^2\\)\n\n\n\n\npour tout \\(u \\in \\mathcal{U}_\\text{UP}\\), l’existence d’un estimateur sans biais \\(\\hat{t}_{y,\\text{HT},u}\\) (sous le deuxième degré) de \\(\\displaystyle t_{y_{(u)}} = \\sum_{k \\in u} y_k\\)\n\n\n\n\npour tout \\(u \\in \\mathcal{U}_\\text{UP}\\), l’existence d’un estimateur sans biais \\(\\hat{\\mathbb{V}}^{2|1}(\\hat{t}_{y,\\text{HT},u})\\) (sous le deuxième degré) de la variance de l’estimateur \\(\\hat{t}_{y,\\text{HT},u}\\).\n\n\n\nSous ces hypothèses, la variance totale de l’estimateur d’Horvitz-Thompson sous le plan \\(p\\) peut être estimée sans biais par \\[\\hat{\\mathbb{V}}^{(1,2)}(\\hat{t}_{y,\\text{HT}}) = \\hat{\\mathbb{V}}^{(1,2)}(\\{ y_{l} : l \\in S_\\text{US} \\}) =  Q(\\hat{t}_{y,\\text{HT},1}, ..., \\hat{t}_{y,\\text{HT},n_{\\text{US}}}) + \\sum_{u \\in S_\\text{UP}} \\left( \\frac{1}{(\\pi_u^{(1)})^2} - q_u \\right) \\hat{\\mathbb{V}}^{2|1}(\\hat{t}_{y,\\text{HT},u})\\]"
  },
  {
    "objectID": "presentations/pres_analytique.html#récapitulatif",
    "href": "presentations/pres_analytique.html#récapitulatif",
    "title": "Atelier du réseau sondage",
    "section": "Récapitulatif",
    "text": "Récapitulatif"
  },
  {
    "objectID": "presentations/pres_analytique.html#estimation-par-subtitution",
    "href": "presentations/pres_analytique.html#estimation-par-subtitution",
    "title": "Atelier du réseau sondage",
    "section": "Estimation par subtitution",
    "text": "Estimation par subtitution\n\n\nNous savons estimer la variance d’estimateurs d’Horvitz-Thompson \\(\\displaystyle \\hat{t}_{y,\\text{HT}} = \\sum_{k \\in S} \\frac{y_k}{\\pi_k}\\) du total.\n\n\n\n\nEn pratique, on s’intéresse à d’autres paramètres (univariés) : \\(\\theta = f(t_{y^{1}}, ..., t_{y^{d}})\\)\n\nExemple 1 : la moyenne de la variable \\(\\{y_k\\}\\) notée \\(\\mu_{y^{1}} = \\frac{1}{N} t_{y^{1}}\\)\nExemple 2 : le rapport des totaux des variables \\(\\{y^{1}_{k}\\}\\) et \\(\\{y^{2}_{k}\\}\\) noté \\(R_{{y^{1}},{y^{2}}} = \\frac{t_{y^{1}}}{t_{y^{2}}}\\)\n\n\n\n\n\nComment trouver un estimateur (approximativement) sans biais ?\n\n\n\n\nPrincipe de subtitution : on remplace les paramètres inconnus par des estimations.\n\nExemple 1 : la moyenne de la variable \\(\\frac{1}{N} \\hat{t}_{y^{1}, \\text{HT}}\\)\nExemple 2 : la moyenne de la variable \\(\\hat{R}_{{y^{1}},{y^{2}}} = \\frac{\\hat{t}_{y^{1}, \\text{HT}}}{\\hat{t}_{y^{2}, \\text{HT}}}\\)\n\n\n\n\n\nQuid de la variance ?"
  },
  {
    "objectID": "presentations/pres_analytique.html#principe-de-linéarisation",
    "href": "presentations/pres_analytique.html#principe-de-linéarisation",
    "title": "Atelier du réseau sondage",
    "section": "Principe de linéarisation",
    "text": "Principe de linéarisation\n\n\nLe principe de linéarisation va permettre d’estimer la variance d’estimateurs par subtitution.\n\n\n\n\nL’idée est d’approximer la variance de l’estimateur par subtitution \\(\\mathbb{V}(f(\\hat{t}_{y^{1,\\text{HT}}, \\text{HT}}, ..., \\hat{t}_{y^{d,\\text{HT}}}))\\) par celle de l’estimateur du total d’Horvitz-Thompson d’une variable \\(\\mathbb{V}(\\hat{t}_{u,\\text{HT}})\\).\n\n\n\n\nComment construire \\(\\{u_k\\}\\) ?\n\n\n\n\nPlusieurs approches différentes :\n\nSi \\(\\hat{\\theta} = f(\\hat{t}_{y^{1,\\text{HT}}, \\text{HT}}, ..., \\hat{t}_{y^{d,\\text{HT}}})\\) où \\(f\\) est différentiable.\nSi \\(\\hat{\\theta}\\) est solution d’une équation estimante.\nSi \\(\\hat{\\theta}\\) est une fonctionnelle."
  },
  {
    "objectID": "presentations/pres_analytique.html#approche-1-si-f-différentiable",
    "href": "presentations/pres_analytique.html#approche-1-si-f-différentiable",
    "title": "Atelier du réseau sondage",
    "section": "Approche 1 : si \\(f\\) différentiable",
    "text": "Approche 1 : si \\(f\\) différentiable\n\nSupposons de plus que \\(f\\) soit régulière : \\(f\\) différentiable.\n\n\n\nEn utilisant un développement de Taylor (cas où \\(f : \\mathbb{R} \\to \\mathbb{R}\\)): \\[f(\\hat{t}_{y,\\text{HT}}) \\approx f(t_y) + (\\hat{t}_{y,\\text{HT}} - t_y) f'(t_y)\\]\n\n\n\n\nPar passage à l’espérance : \\[\\mathbb{E}(f(\\hat{t}_{y,\\text{HT}})) \\approx \\mathbb{E}(f(t_y)) + \\mathbb{E}((\\hat{t}_{y,\\text{HT}} - t_y) f'(t_y)) \\approx \\mathbb{E}(f(t_y))\\] \\(\\to\\) Si l’estimateur d’Horvitz-Thompson \\(\\hat{t}_{y,\\text{HT}}\\) est sans biais pour \\(t_y\\) alors \\(f(t_{y,\\text{HT}})\\) l’est approximativement pour \\(f(t_{y})\\). \n\n\n\n\nPar passage à la variance : \\[\\mathbb{V}(f(\\hat{t}_{y,\\text{HT}})) \\approx \\mathbb{V}((\\hat{t}_{y,\\text{HT}} - t_y) f'(t_y)) \\approx  \\color{red}{\\mathbb{V}((\\hat{t}_{ f'(t_y) \\times y,\\text{HT}}))}\\]\n\n\n\n\nThéorème 1 (Biais de l’estimateur par subtitution) Si l’estimateur d’Horvitz-Thompson \\(\\hat{t}_{y,\\text{HT}}\\) est sans biais pour \\(t_y\\) alors \\(\\mathbb{E}(f(\\hat{t}_{y,\\text{HT}})) - f(t_y) \\approx 0\\)."
  },
  {
    "objectID": "presentations/pres_analytique.html#approche-1-si-f-différentiable-1",
    "href": "presentations/pres_analytique.html#approche-1-si-f-différentiable-1",
    "title": "Atelier du réseau sondage",
    "section": "Approche 1 : si \\(f\\) différentiable",
    "text": "Approche 1 : si \\(f\\) différentiable\n\n\nLa variance d’un estimateur de la forme \\(f(\\hat t_{y,\\text{HT}})\\) est approximativement égale à la variance de l’estimateur du total de la variable \\(\\{u_k\\}\\) définie pour tout individu \\(k, ~~ u_k = f'(t_y) \\times y_k\\) : \\[ \\mathbb{V}(f(\\hat t_{y,\\text{HT}})) \\approx \\mathbb{V}(\\hat t_{u,HT}) \\]\n\n\n\n\nIntuitivement : la variance de \\(f(\\hat t_{y,\\text{HT}})\\) est approximativement la même que celle d’un estimateur d’Horvitz-Thompson pour une variable d’intérêt bien choisie \\(\\to\\) rôle central de l’estimation du total.\n\n\n\n\nLa variable \\(\\{u_k\\}\\) est appelée variable linéarisée associée à \\(f\\).\n\n\n\n\nProblème : cette variable est définie pour tout individu \\(k \\in \\mathcal{U} ~~ u_k = f'(\\color{red}{t_y}\\color{black}) \\times y_k \\to\\) il est donc nécessaire de connaître \\(\\displaystyle t_y = \\sum_{k \\in \\mathcal{U}} y_k\\) qui est inconnu.\n\n\n\n\nSolution : estimer par subtitution la variable linéarisée \\(\\{u_k\\}\\).\n\nPour l’individu \\(k \\in \\mathcal{U}\\), \\(u_k = f'(t_y) \\times y_k\\) sera estimé par \\(\\hat{u}_k = f'(\\hat{t}_{y,\\text{HT}}) \\times y_k\\).\n\n\n\n\n\nLa variable \\(\\hat{u}_k\\) est la variable linéarisée estimée.\n\n\n\n\nThéorème 2 (Estimation de la variance par linéarisation - cas unidimensionnel) L’estimateur de la variance par linéarisation d’une fonction d’intérêt de la forme \\(f(t_{y})\\) est donné par \\(\\displaystyle \\hat{\\mathbb{V}}_\\text{lin}(f(\\hat{t}_{y,\\text{HT}})) = \\hat{\\mathbb{V}}(\\hat t_{\\hat{u},HT})\\)"
  },
  {
    "objectID": "presentations/pres_analytique.html#exemple-de-linéarisation---cas-unidimensionnel",
    "href": "presentations/pres_analytique.html#exemple-de-linéarisation---cas-unidimensionnel",
    "title": "Atelier du réseau sondage",
    "section": "Exemple de linéarisation - cas unidimensionnel",
    "text": "Exemple de linéarisation - cas unidimensionnel\n\n\nOn suppose que l’échantillon \\(S\\) dont nous disposons soit tiré selon un plan de sondage tel que pour tout individu \\(k \\in \\mathcal{U}, ~ \\pi_k &gt; 0\\) \\(\\to\\) l’estimateur du total d’Horvitz-Thompson \\(\\hat{t}_{y,\\text{HT}}\\) est un estimateur sans biais de \\(t_y\\).\n\n\n\n\n\nDans cet exemple, la variable d’intérêt prend des valeurs strictement positives.\n\n\n\n\nNous souhaitons estimer \\(\\log{t_y}\\) : un estimateur par subtitution est donné par \\(\\log{\\hat{t}_{y,\\text{HT}}}\\).\n\n\n\n\nCet estimateur est approximativement sans biais pour \\(\\log{t_y}\\) car \\(\\hat{t}_{y,\\text{HT}}\\) est sans biais pour \\(t_y\\).\n\n\n\n\nL’estimateur de la variance par linéarisation est donné par \\(\\hat{\\mathbb{V}}(\\hat t_{\\hat{u},HT})\\) où pour tout \\(k \\in \\mathcal{U}\\), \\(\\hat{u}_k = \\frac{y_k}{\\hat{t}_{y,\\text{HT}}}\\).\n\nIl reste à utiliser les résultats propres au plan de sondage afin de déterminer un estimateur de la variance."
  },
  {
    "objectID": "presentations/pres_analytique.html#linéarisation-dune-fonction-de-plusieurs-totaux",
    "href": "presentations/pres_analytique.html#linéarisation-dune-fonction-de-plusieurs-totaux",
    "title": "Atelier du réseau sondage",
    "section": "Linéarisation d’une fonction de plusieurs totaux",
    "text": "Linéarisation d’une fonction de plusieurs totaux\n\n\nIl est possible d’utiliser cette approche pour des fonctions de totaux de plusieurs variables d’intérêt \\(f(t_{y^1}, ..., t_{y^d})\\) où \\(f : \\mathbb{R}^d \\to \\mathbb{R}\\) est une fonction différentiable.\n\n\n\n\nPrincipe de subtitution : un estimateur de \\(\\theta := f(t_{y^1}, ..., t_{y^d})\\) est donné par \\(\\hat{\\theta} := f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d,\\text{HT}}})\\).\n\n\n\n\nMême idée : en utilisant la formule de Taylor \\[f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d,\\text{HT}}}) \\approx f(t_{y^1}, ..., t_{y^d}) +  ( \\hat{t}_{y^1, \\text{HT}} - t_{y^1} , ..., \\hat{t}_{y^d,\\text{HT}} - t_{y^d}) \\nabla f(t_{y^1}, ..., t_{y^d})\\]\n\n\n\n\nIl est possible d’obtenir l’approximation de la variance suivante : \\[\\mathbb{V}(f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d,\\text{HT}}})) \\approx \\mathbb{V}(  ( \\hat{t}_{y^1, \\text{HT}}  , ..., \\hat{t}_{y^d,\\text{HT}}) \\nabla f(t_{y^1}, ..., t_{y^d})   ) = \\hat{t}_{u,\\text{HT}}\\]\n\noù la variable \\(\\{u_k\\}_{k \\in \\mathcal{U}}\\) est définie pour tout \\(k \\in \\mathcal{U}\\) par \\(u_k =  (y^1_k, ..., y^d_k) \\nabla f(t_{y^1}, ..., t_{y^d})\\)\n\n\n\n\\(u_k\\) est la variable linéarisée associée à \\(f\\) \\(\\to\\) même problème que dans les cas univarié : pas accès aux totaux."
  },
  {
    "objectID": "presentations/pres_analytique.html#linéarisation-dune-fonction-de-plusieurs-totaux-2",
    "href": "presentations/pres_analytique.html#linéarisation-dune-fonction-de-plusieurs-totaux-2",
    "title": "Atelier du réseau sondage",
    "section": "Linéarisation d’une fonction de plusieurs totaux (2)",
    "text": "Linéarisation d’une fonction de plusieurs totaux (2)\n\n\n\\(u_k\\) est la variable linéarisée associée à \\(f\\) \\(\\to\\) même problème que dans les cas univarié : pas accès aux totaux.\n\n\\(\\to\\) utilisation de la variable linéarisée estimée : \\(\\hat u_k = \\nabla f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{y^d,\\text{HT}}) (y^1_k, ..., y^d_k)^T\\).\n\n\n\nEstimation par subtitution : \\(\\hat{\\mathbb{V}}_\\text{lin}(f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d,\\text{HT}}})) =  \\hat{\\mathbb{V}}(  ( \\hat{t}_{y^1, \\text{HT}} , ..., \\hat{t}_{y^d,\\text{HT}} ) \\nabla f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d},\\text{HT}})) = \\mathbb{V}(\\hat{t}_{\\hat{u},\\text{HT}})\\)\n\n\n\n\nThéorème 3 (Estimation de la variance par linéarisation) L’estimateur de la variance par linéarisation d’une fonction d’intérêt de la forme \\(f(t_{y^1}, ..., t_{y^d})\\) est donné par \\(\\displaystyle \\hat{\\mathbb{V}}_\\text{lin}(f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d,\\text{HT}}})) = \\mathbb{V}(  ( \\hat{t}_{y^1, \\text{HT}} , ..., \\hat{t}_{y^d,\\text{HT}}) \\nabla f(\\hat{t}_{y^1,\\text{HT}}, ..., \\hat{t}_{{y^d},\\text{HT}}))\\)"
  },
  {
    "objectID": "presentations/pres_analytique.html#exemple-de-linéarisation",
    "href": "presentations/pres_analytique.html#exemple-de-linéarisation",
    "title": "Atelier du réseau sondage",
    "section": "Exemple de linéarisation",
    "text": "Exemple de linéarisation\n\nSupposons que nous disposons de deux variables d’intérêt \\(y^{1}\\) (par exemple, les dépenses alimentaires) et \\(y^{2}\\) (par exemple, le revenu total) et que nous souhaitons connaître un estimateur du ratio des totaux \\(R_{y^{1}, y^{2}} = \\frac{t_{y^{1}}}{t_{y^{2}}}\\).\nL’estimateur par subtitution de \\(R_{y^{1}, y^{2}}\\) noté \\(\\hat{R}_{y^{1}, y^{2}}\\) est donné par \\(\\hat{R}_{y^{1}, y^{2}} = \\frac{\\hat{t}_{y^{1},\\text{HT}}}{\\hat{t}_{y^{2},\\text{HT}}}\\) .\nCet estimateur est approximativement sans biais (le biais est d’autant plus faible que les estimateurs des totaux ont une faible variance et que la fonction d’intérêt ne fluctue pas trop - on suppose que pour tout \\(k \\in \\mathcal{U}, \\pi_k &gt; 0\\)).\nQuid de la variance ?\n\nMalheureusement, \\(\\mathbb{V}(\\hat{R}_{y^{1}, y^{2}}) = \\mathbb{V}(\\frac{\\hat{t}_{y^{(1)},\\text{HT}}}{\\hat{t}_{y^{(2)},\\text{HT}}}) \\neq  \\frac{\\mathbb{V}(\\hat{t}_{y^{(1)},\\text{HT}})}{\\mathbb{V}({\\hat{t}_{y^{(2)},\\text{HT}})}}\\)\nUtilisation du principe de substitution."
  },
  {
    "objectID": "presentations/pres_analytique.html#exemple-de-linéarisation-2",
    "href": "presentations/pres_analytique.html#exemple-de-linéarisation-2",
    "title": "Atelier du réseau sondage",
    "section": "Exemple de linéarisation (2)",
    "text": "Exemple de linéarisation (2)\n\n\n\\(f : (x,y) \\in \\mathbb{R} \\times \\mathbb{R}^* \\to \\frac{x}{y}\\)\n\n\n\n\nPour tout \\((x,y) \\in \\mathbb{R} \\times \\mathbb{R}^*\\), \\(\\nabla f(x,y) = (\\frac{1}{y}, \\frac{-x}{y})^T\\)\n\n\n\n\nLa variable linéarisée pour un individu \\(k\\) vaut donc \\(u_k = \\frac{y^{1}_k}{t_{y^{2}}} - \\frac{t_{y^{1}}}{t_{y^{2}}^2} y^{2}_k = \\frac{1}{t_{y^{2}}} (y^{1}_k - R_{y^{1}, y^{2}} y^{2}_k)\\)\n\n\n\n\nLa variable linéarisée estimée pour un individu \\(k\\) vaut \\(\\hat{u}_k =  \\frac{1}{\\hat{t}_{y^{2},\\text{HT}}} (y^{1}_k - \\hat{R}_{y^{1}, y^{2}} y^{2}_k)\\)\n\n\nL’estimateur de la variance par linéarisation de \\(\\mathbb{V}(\\hat{R}_{y^1, y^2, \\text{sub}})\\) est \\(\\hat{\\mathbb{V}}(\\hat{t}_{\\hat{u}, \\text{HT}})\\) où \\(\\hat{u}_k =  \\frac{1}{\\hat{t}_{y^{2},\\text{HT}}} (y^{1}_k - \\hat{R}_{y^{1}, y^{2}} y^{2}_k)\\)."
  },
  {
    "objectID": "presentations/pres_analytique.html#linéarisation-par-fonction-objective",
    "href": "presentations/pres_analytique.html#linéarisation-par-fonction-objective",
    "title": "Atelier du réseau sondage",
    "section": "Linéarisation par fonction objective",
    "text": "Linéarisation par fonction objective\n\n\nCertains paramètres d’intérêt et estimateurs sont solutions d’une équation estimante.\n\n\n\n\nDans certains cas, une expression close du paramètre ou de l’estimateur n’existe pas.\n\nIl n’est pas possible de donner une expression directe de l’estimateur.\n\n\n\n\n\nIl est cependant possible d’obtenir une estimation de la variance de l’estimateur par linéarisation de la fonction objective.\n\n\n\n\nSoit \\(\\theta \\in \\mathbb{R}^d\\), un paramètre tel que \\[\\begin{equation}\n\\frac{1}{N} \\sum_{k \\in \\mathcal{U}} \\phi(\\theta; x_k, y_k) = 0 \\text{  où  } \\phi : \\mathbb{R}^d \\to \\mathbb{R}^{d} \\text{ différentiable.}\n\\label{defparameq}\n\\end{equation}\\]\n\nExemple 1 : la moyenne \\(\\displaystyle {\\mu}_y = \\frac{1}{N} \\sum_{k \\in \\mathcal{U}} y_k\\) avec \\(\\phi(\\theta; x_k, y_k) = y_k - \\theta\\)\nExemple 2 : le coefficient de régression \\(\\beta\\) de la régression de \\(\\{y_k\\}\\) sur \\(\\{x_k\\}\\) avec \\(\\phi(\\theta; x_k, y_k) = x_k (y_k - x_k^T \\theta)\\)"
  },
  {
    "objectID": "presentations/pres_analytique.html#linéarisation-par-fonction-objective-1",
    "href": "presentations/pres_analytique.html#linéarisation-par-fonction-objective-1",
    "title": "Atelier du réseau sondage",
    "section": "Linéarisation par fonction objective",
    "text": "Linéarisation par fonction objective\n\nIl est possible de construire un estimateur associé \\(\\hat{\\theta}\\) tel que \\[\\begin{equation}\n\\frac{1}{N} \\sum_{k \\in S} \\frac{\\phi(\\hat{\\theta}; x_k, y_k)}{\\pi_k} = 0 \\text{  où  } \\phi : \\mathbb{R}^d \\to \\mathbb{R}^{d} \\text{ différentiable.}\n\\label{defestimeq}\n\\end{equation}\\]\n\nExemple 1 : l’estimateur \\(\\displaystyle \\hat{\\mu}_{y, \\text{Hayek}} = \\frac{1}{\\sum_{k \\in S}\\frac{1}{\\pi_k}} \\sum_{k \\in S} \\frac{y_k}{\\pi_k}\\) avec \\(\\phi(\\theta; x_k, y_k) = y_k - \\theta\\)\nExemple 2 : le coefficient de régression estimée \\(\\displaystyle \\hat{\\beta} = \\left(\\sum_{k \\in S} \\frac{x_k x_k^T}{\\pi_k} \\right)^{-1} \\sum_{k \\in S} \\frac{x_k y_k}{\\pi_k}\\) de la régression de \\(y\\) sur \\(x\\) avec \\(\\phi(\\theta; x_k, y_k) = x_k (y_k - x_k^T \\theta)\\)"
  },
  {
    "objectID": "presentations/pres_analytique.html#intuition-de-la-linéarisation-par-fonction-estimante",
    "href": "presentations/pres_analytique.html#intuition-de-la-linéarisation-par-fonction-estimante",
    "title": "Atelier du réseau sondage",
    "section": "Intuition de la linéarisation par fonction estimante",
    "text": "Intuition de la linéarisation par fonction estimante\n\nSi \\(\\phi\\) est différentiable, \\[\\phi(\\hat{\\theta}; x_k, y_k) \\approx \\phi(\\theta; x_k, y_k) + (\\text{Jac}(\\phi)(\\theta)) (\\hat{\\theta} - \\theta)\\]\nD’où \\[\\underbrace{\\sum_{k \\in S} \\frac{\\phi(\\hat{\\theta}; x_k, y_k)}{\\pi_k}}_{=0} \\approx \\sum_{k \\in S} \\frac{\\phi(\\theta; x_k, y_k)}{\\pi_k} + (\\sum_{k \\in S} \\frac{\\text{Jac}(\\phi)(\\theta; x_k, y_k))}{\\pi_k}) (\\hat{\\theta} - \\theta)\\]\nD’où \\((-\\sum_{j \\in \\mathcal{U}} {\\text{Jac}(\\phi)(\\theta; x_j, y_j))})\\) inversible : \\[\\begin{align}\n(\\hat{\\theta} - \\theta) &\\approx \\sum_{k \\in S}  (-\\sum_{j \\in S} \\frac{\\text{Jac}(\\phi)(\\theta; x_j, y_j))}{\\pi_j})^{-1} \\frac{\\phi(\\theta; x_k, y_k)}{\\pi_k} \\\\\n&\\approx \\sum_{k \\in S}  (-\\sum_{j \\in \\mathcal{U}} {\\text{Jac}(\\phi)(\\theta; x_j, y_j))})^{-1} \\frac{\\phi(\\theta; x_k, y_k)}{\\pi_k} \\\\\n&\\approx \\sum_{k \\in S} \\frac{u_k(\\theta)}{\\pi_k}\n\\end{align}\\]"
  },
  {
    "objectID": "presentations/pres_analytique.html#section-3",
    "href": "presentations/pres_analytique.html#section-3",
    "title": "Atelier du réseau sondage",
    "section": "",
    "text": "Théorème 4 (Estimateur de la variance par linéarisation de l’équation estimante) L’approximation suivante \\(\\displaystyle \\mathbb{V}(\\hat{\\theta}) \\approx \\mathbb{V}(\\sum_{k \\in S} \\frac{u_k(\\theta)}{\\pi_k})\\) permet de créer un estimateur \\(\\displaystyle \\hat{\\mathbb{V}}(\\hat{\\theta}) \\approx \\hat{\\mathbb{V}}(\\sum_{k \\in S} \\frac{\\widehat{u_k(\\theta)}}{\\pi_k})\\)\n\n\n\n\nLa variable \\(\\{ u_k(\\theta) \\}\\) est la variable linéarisée associée à l’estimateur \\(\\hat{\\theta}\\) \\(\\to\\) \\(\\theta\\) est inconnu.\n\n\n\n\nLa variable \\(\\{ u_k(\\hat{\\theta}) \\}\\) est la variable linéarisée estimée associée à l’estimateur."
  },
  {
    "objectID": "presentations/pres_analytique.html#exemple-dapplication",
    "href": "presentations/pres_analytique.html#exemple-dapplication",
    "title": "Atelier du réseau sondage",
    "section": "Exemple d’application",
    "text": "Exemple d’application\n\nExemple 2 : le coefficient de régression estimée \\(\\displaystyle \\hat{\\beta} = \\left(\\sum_{k \\in S} \\frac{x_k x_k^T}{\\pi_k} \\right)^{-1} \\sum_{k \\in S} \\frac{x_k y_k}{\\pi_k}\\) de la régression de \\(y\\) sur \\(x\\) avec \\(\\phi(\\theta; x_k, y_k) = x_k (y_k - x_k^T \\theta)\\)\n\\(\\text{Jac}(\\phi)(\\theta; x_j, y_j) = x_k x_k^T\\)\n\\(u_k^\\text{est}(\\theta) = \\left(- \\sum_{k \\in \\mathcal{U}} x_j x_j^T \\right)^{-1} {x_k}({y_k - x_k^T \\theta})\\)\nApplication de l’estimateur \\(\\displaystyle \\hat{\\mathbb{V}}\\) de la variance d’un total à \\(\\widehat{u_k^\\text{est}(\\hat{\\beta})} = \\left(- \\sum_{k \\in S} \\frac{x_j x_j^T}{\\pi_k} \\right)^{-1} {x_k}({y_k - x_k^T \\hat{\\beta}})\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nIl s’agit d’une version allégée de la linéarisation sur équation estimante : beaucoup d’hypothèses ont été cachées.\nCes hypothèses sont parfois techniques et difficilement vérifiables en pratique.\nNe pas hésitez à vérifier l’implémentation des estimations par linéarisation sur des exemples simples en utilisant des simulations."
  },
  {
    "objectID": "presentations/pres_analytique.html#récapitulatif-1",
    "href": "presentations/pres_analytique.html#récapitulatif-1",
    "title": "Atelier du réseau sondage",
    "section": "Récapitulatif",
    "text": "Récapitulatif\n\nRécapitulatif"
  },
  {
    "objectID": "presentations/pres_analytique.html#calage-sur-marges",
    "href": "presentations/pres_analytique.html#calage-sur-marges",
    "title": "Atelier du réseau sondage",
    "section": "Calage sur marges",
    "text": "Calage sur marges\n\n\nLa calage sur marges consiste à chercher les poids les plus proches des poids initiaux en respectant des contraintes sur l’estimation des marges.\n\n\n\n\nFormellement, les poids calés sont solution du programme d’optimisation : \\[\\min_{w \\in \\mathbb{R}^n} \\sum_{k \\in S} d_k G(\\frac{w_k}{d_k}) \\text{ sous contrainte que } \\sum_{k \\in S} w_k \\textbf{x}_k = t_\\textbf{x}\\] où \\(G\\) est une pseudo-distance/divergence qui quantifie l’écart entre les poids initiaux et les poids calés.\n\n\n\n\nL’estimateur calé du total d’une variable \\(\\{y_k\\}\\) s’écrit \\(\\displaystyle \\hat{t}_{y,\\text{cal}} = \\sum_{k \\in S} w_k(\\color{red}S\\color{black}) y_k\\) \\(\\to\\) il n’est pas possible d’utiliser les estimateurs de la variance d’un estimateur du total classique. 😢\n\n\n\n\nDeville et Sarndal (1992)1 montre qu’il est possible d’approximer la variance d’un estimateur calé en utilisant :\n\nun estimateur de la variance d’un estimateur du total classique. 😁\nles résidus de la régression de la variable d’intérêt \\(\\{y_k\\}\\) sur \\(\\{\\textbf{x}_k\\}\\) pondérée par les poids initiaux.\n\n\n\n\n\nPas de dépendances au choix de \\(G\\)2 : toutes les méthodes sont asymptotiquement équivalentes au sens de la variance.\n\n\nKim et Park (2010) pour une lecture plus détaillée.Pour les formes usuelles."
  },
  {
    "objectID": "presentations/pres_analytique.html#calage-sur-marges-1",
    "href": "presentations/pres_analytique.html#calage-sur-marges-1",
    "title": "Atelier du réseau sondage",
    "section": "Calage sur marges",
    "text": "Calage sur marges\n\nThéorème 5 (Estimation de la variance d’un estimateur du total calé) L’estimateur de la variance d’un estimateur du total calé est \\(\\hat{\\mathbb{V}}^\\text{cal}(\\hat{t}_{y,\\text{cal}}) = \\hat{\\mathbb{V}}(\\hat{t}_{\\varepsilon,\\text{HT}})\\) où \\(\\hat{\\mathbb{V}}\\) est un estimateur de la variance d’un estimateur du total d’Horvitz-Tompson et \\(\\{\\varepsilon_k\\}\\) désigne les résidus de la régression pondérée de \\(\\{y_k\\}\\) sur \\(\\{x_k\\}\\).\n\n\ngustave dispose d’une fonction permettant de récupérer les résidus de la régression :\n\nExemple d’un estimateur calé tiré selon un \\(\\text{SASSR}(100;200)\\)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/pres_analytique.html#récapitulatif-2",
    "href": "presentations/pres_analytique.html#récapitulatif-2",
    "title": "Atelier du réseau sondage",
    "section": "Récapitulatif",
    "text": "Récapitulatif\n\nRécapitulatif"
  },
  {
    "objectID": "presentations/pres_analytique.html#partage-des-poids",
    "href": "presentations/pres_analytique.html#partage-des-poids",
    "title": "Atelier du réseau sondage",
    "section": "Partage des poids",
    "text": "Partage des poids\n\n\n\n\n\nPartage des poids\n\n\n\n\nLe partage des poids permet de calculer les poids lorsque :\n\nLe plan de sondage est indirect,\nPlusieurs bases de sondage sont mobilisées,\nUn panel est utilisé.\n\nCette méthode permet de prendre en compte qu’un individu de la population-fille aurait pu être tiré de plusieurs manières / à plusieurs instants différents.\n\\(L_{ij} = 1\\) si l’individu \\(i\\) est la mère de l’individu \\(j\\) et \\(\\displaystyle L_{\\bullet j} = \\sum_{k \\in \\color{red} \\mathcal{U} \\color{black}} L_{kj}\\).\nApplication : le poids d’un ménage \\(j \\in S_\\text{fille}\\) est \\(\\displaystyle w^\\text{fille}_{j} = \\sum_{k \\in \\mathcal{U_\\text{mère}}} w^\\text{mère}_{k} \\frac{L_{kj}}{L_{\\bullet j}}I^\\text{mère}_k\\)\nApplication à l’estimation de la variance : \\[\\mathbb{V}(\\sum_{j \\in S_\\text{fille}} w^\\text{fille}_{j} y_j) = \\mathbb{V}(\\sum_{k \\in S_\\text{mère}} w^\\text{mère}_{k} z_k)\\] où \\(\\displaystyle z_k = \\sum_{j \\in S_\\text{fille}} \\frac{L_{kj}}{L_{\\bullet j}} y_i\\)"
  },
  {
    "objectID": "presentations/pres_analytique.html#récapitulatif-3",
    "href": "presentations/pres_analytique.html#récapitulatif-3",
    "title": "Atelier du réseau sondage",
    "section": "Récapitulatif",
    "text": "Récapitulatif\n\nRécapitulatif"
  },
  {
    "objectID": "presentations/pres_analytique.html#il-était-une-fois-gustave",
    "href": "presentations/pres_analytique.html#il-était-une-fois-gustave",
    "title": "Atelier du réseau sondage",
    "section": "Il était une fois, gustave …",
    "text": "Il était une fois, gustave …\n\ngustave est un package développé en R à l’Insee en 2018.\nIl permet de :\n\nAider au calcul de variance,\nProposer un cadre consistant,\nRéutiliser des opérations déjà implementées,\nDiffuser les résultats sans que l’utilisateur ait besoin de connaissance en sondage.\n\nCe que gustave n’est pas :\n\nUn package qui estime automatiquement la variance fonctionnant pour tous les plans.\n\n\n\n\n\n\n\n\nImportant\n\n\nUn package proposant une estimation de la variance basée uniquement sur des poids (sans autre prise en compte du plan de sondage) se base a priori sur des hypothèses (trop ?) simplificatrices."
  },
  {
    "objectID": "presentations/pres_analytique.html#variance-wrapper",
    "href": "presentations/pres_analytique.html#variance-wrapper",
    "title": "Atelier du réseau sondage",
    "section": "variance wrapper",
    "text": "variance wrapper\n\nLes estimations de variance sont livrées sous la forme de fonction : les variance wrappers.\nCes fonctions permettent à l’utilisateur, à partir de ces données, d’obtenir une estimation de la variance mais aussi des intervalles de confiance.\nPas besoin de chercher les données nécessaires (dans les méandres de nos coffres) : toutes les données sont cachées1 dans la fonction.\n\n\n\n\n\n\n\nImportant\n\n\nPour certaines enquêtes, il est nécessaire de mobiliser des informations potentiellement confidentielles durant l’estimation de la variance (par exemple, des variables de calage sensibles) : la diffusion de la fonction variance wrapper entraîne la diffusion de ces données.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nElles sont dans l’environnement associé à la fonction."
  },
  {
    "objectID": "presentations/pres_analytique.html#construction-dun-variance-wrapper",
    "href": "presentations/pres_analytique.html#construction-dun-variance-wrapper",
    "title": "Atelier du réseau sondage",
    "section": "Construction d’un variance wrapper",
    "text": "Construction d’un variance wrapper\n\nComment ces estimations sont calculées ?\nComment construire ce variance wrapper ? \nTravail méthodologique en amont :\n\nProposition d’un estimateur de la variance d’un estimateur du total (calé, Hovitz-Thompson, …) :\n\nOn pourra utiliser les résultats sur l’estimation de variance de l’estimateur calé, par tirage indirect …\n\nImplémentation sous la forme d’une fonction simple en R / les données utilisées dans ce calcul seront stockées dans une liste.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/pres_analytique.html#construction-dun-variance-wrapper-1",
    "href": "presentations/pres_analytique.html#construction-dun-variance-wrapper-1",
    "title": "Atelier du réseau sondage",
    "section": "Construction d’un variance wrapper",
    "text": "Construction d’un variance wrapper\n\nCréation d’un variance wrapper à partir de cette fonction qui :\n\nAidera à gérer les linéarisations,\nIncorporera les données.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPour la diffusion, il suffit de livrer le variance_wrapper :\n\nPar exemple, en enregistrant la fonction dans un fichier .rData."
  },
  {
    "objectID": "presentations/pres_analytique.html#récapitulatif-4",
    "href": "presentations/pres_analytique.html#récapitulatif-4",
    "title": "Atelier du réseau sondage",
    "section": "Récapitulatif",
    "text": "Récapitulatif"
  },
  {
    "objectID": "presentations/pres_analytique.html#linéarisation-et-statistic-wrapper",
    "href": "presentations/pres_analytique.html#linéarisation-et-statistic-wrapper",
    "title": "Atelier du réseau sondage",
    "section": "Linéarisation et statistic wrapper",
    "text": "Linéarisation et statistic wrapper\n\nComment gustave sait commment linéariser les fonctions d’intérêt ?\nUtilisation des statistic wrapper - fonction permettant de :\n\nCalculer un estimateur d’une fonction d’intérêt à partir des variables d’intérêt et d’autres données.\nCalculer la linéarisée estimée.\n\ngustave contient de base plusieurs statistic wrapper :\n\ngustave:::mean, gustave:::total, gustave:::ratio, gustave:::diff_of_ratio …\nMais comment faire si on souhaite estimer d’autres paramètres ? 😢\n\nIl est possible d’en définir simplement avec la fonction define_statistic_wrapper."
  },
  {
    "objectID": "presentations/pres_analytique.html#exemple-de-définition-dun-statistic-wrapper",
    "href": "presentations/pres_analytique.html#exemple-de-définition-dun-statistic-wrapper",
    "title": "Atelier du réseau sondage",
    "section": "Exemple de définition d’un statistic wrapper",
    "text": "Exemple de définition d’un statistic wrapper\n\n(Re)-définition d’un statistic wrapper pour la linéarisée du ratio : ratio2\ndefine_statistic_wrapper nécessite de renseigner :\n\nune fonction calculant la fonction d’intérêt et les linéarisées estimées. Cette fonction renvoie une liste avec a minima deux éléments nommés :\n\npoint : Estimation ponctuelle de la fonction d’intérêt.\nlin : Vecteur contenant la linéarisée estimée.\n\nune liste contenant pour chaque argument de la fonction en argument de statistic_function un type parmi \"num\", \"denom\" ou \"weights\"\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/pres_analytique.html#bibliographie",
    "href": "presentations/pres_analytique.html#bibliographie",
    "title": "Atelier du réseau sondage",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nBerger, Yves G. 1998. « Rate of convergence for asymptotic variance of the Horvitz–Thompson estimator ». Journal of Statistical Planning and Inference 74: 149‑68.\n\n\nChauvet, Guillaume. 2015. « Coupling methods for multistage sampling ». Annals of Statistics 43: 2484‑2506.\n\n\nDeville, Jean-Claude, et Carl-Erik Sarndal. 1992. « Calibration Estimators in Survey Sampling ». Journal of the American Statistical Association 87 (418): 376‑82. http://www.jstor.org/stable/2290268.\n\n\nDeville, Jean-Claude, et Yves Tillé. 2000. « Echantillonnage équilibre par la méthode du cube, variance et estimation ». Acte des JMS.\n\n\nHájek, Jaroslav. 1960. « Limiting distributions in simple random sampling from a finite population ». Publications of the Mathematical Institute of the Hungarian Academy of Sciences 5: 361‑74.\n\n\nKim, Jae Kwang, et Mingue Park. 2010. « Calibration Estimation in Survey Sampling ». International Statistical Review / Revue Internationale de Statistique 78 (1): 21‑39. http://www.jstor.org/stable/27919793.\n\n\nRao, JNK. 1975. « Unbiased variance estimation for multistage designs ». Sankhya."
  },
  {
    "objectID": "presentations/pres_analytique.html#sec-icidd",
    "href": "presentations/pres_analytique.html#sec-icidd",
    "title": "Atelier du réseau sondage",
    "section": "Annexe 1 : Rappel sur les intervalles de confiance",
    "text": "Annexe 1 : Rappel sur les intervalles de confiance\n\n\n\n\nIntervalle de confiance\n\n\nUn intervalle de confiance (resp. par excès) de niveau \\(1 - \\alpha\\) pour le paramètre \\(\\theta\\) est un intervalle défini par deux variables aléatoires \\(\\underline{\\hat \\theta}\\) et \\(\\bar{\\hat \\theta}\\) telles que \\[\\mathbb{P}(\\theta \\in [\\underline{\\hat \\theta}, \\bar{\\hat \\theta}]) = 1 - \\alpha \\text{ (resp } \\geq 1 - \\alpha)\\]\n\n\n\n\n\n\n\n\nIntervalle de confiance asymptotique\n\n\nUn intervalle de confiance asymptotique (resp. par excès) de niveau \\(1 - \\alpha\\) pour le paramètre \\(\\theta\\) est un intervalle défini par deux suites de variables aléatoires \\((\\underline{\\hat \\theta_n})_{n \\in \\mathbb{N}}\\) et \\((\\bar{\\hat \\theta_n})_{n \\in \\mathbb{N}}\\) telles que \\[\\lim_{n \\to \\infty} \\mathbb{P}(\\theta \\in [\\underline{\\hat \\theta_n}, \\bar{\\hat \\theta_n}]) = 1 - \\alpha \\text{ (resp } \\geq 1 - \\alpha)\\]\n\n\n\n\n\nGénéralement :\n\nles intervalles de confiance non asymptotiques sont utilisables si on connaît la distribution de l’échantillon.\nles intervalles de confiance asymptotique repose sur la normalité asymptotique de l’estimateur :\n\ndans le cadre traditionnel (population infinie, iid) : le théorème central limite."
  },
  {
    "objectID": "presentations/pres_analytique.html#théorème-central-limite",
    "href": "presentations/pres_analytique.html#théorème-central-limite",
    "title": "Atelier du réseau sondage",
    "section": "Théorème central limite",
    "text": "Théorème central limite\n\n\n\nThéorème central limite - cadre hors sondage\n\n\nSoit \\(\\{X_1, ..., X_n\\}\\), \\(n\\) variables aléatoires iid telles que \\(\\mathbb{E}(X_1) = \\mu\\) et \\(\\mathbb{V}(X_1) &lt; \\infty\\). Le théorème central limite assure que : \\[\\frac{1}{\\mathbb{V}( \\frac{1}{n} \\sum_{k = 1}^n X_k)^{\\frac{1}{2}}} \\left( \\frac{1}{n} \\sum_{k = 1}^n X_k - \\mu \\right) = \\frac{\\sqrt{n}}{\\mathbb{V}(X_1)^{\\frac{1}{2}}} \\left( \\frac{1}{n} \\sum_{k = 1}^n X_k - \\mu \\right) \\hookrightarrow \\mathcal{N}(0, 1)\\] où \\(\\hookrightarrow\\) désigne la convergence en loi.\n\n\n\n\n\n\n\n\nUtilisation possible pour déterminer un intervalle de confiance asymptotique pour l’espérance\n\\[[\\bar{X_n} - \\frac{\\mathbb{V}(X_1)^{\\frac{1}{2}}}{\\sqrt{n}} q_{1 - \\frac{\\alpha}{2}} , \\bar{X_n} + \\frac{\\mathbb{V}(X_1)^{\\frac{1}{2}}}{\\sqrt{n}} q_{1 - \\frac{\\alpha}{2}} ]\\] où \\(q_{1 - \\frac{\\alpha}{2}}\\) est le quantile d’ordre \\(1-\\frac{\\alpha}{2}\\) de la loi normale centrée réduite, est un intervalle de confiance asymptotique au niveau \\(1-\\alpha\\) pour \\(\\bar{X}_n\\).\n\n\n\nRetour au cours"
  },
  {
    "objectID": "presentations/var_gustave.html",
    "href": "presentations/var_gustave.html",
    "title": "Estimation de variance analytique avec gustave",
    "section": "",
    "text": "gustave est un package permettant d’estimer la variance d’estimateurs dans un contexte d’échantillonnage en population finie. Ce package s’inscrit dans une logique d’harmonisation des programmes à l’Insee introduite avec la macro Calker en SAS. Ce package simplifie les estimations de variance analytique en mutualisant des opérations mobilisées dans plusieurs enquêtes et en imposant une distinction entre les enjeux méthodologiques et de diffusion. gustave garde un niveau d’abstraction suffisant afin de pouvoir ajouter simplement des spécificités propres à certaines enquêtes.\nL’estimation de la variance avec gustave peut se décomposer en trois étapes : calcul d’un estimateur de la variance d’un estimateur d’un total, implémentation de l’estimateur et utilisation des variables linéarisées.\nAfin d’illustrer le cheminement permettant d’obtenir les estimations de variance avec gustave, nous proposons d’estimer la précision dans le cadre d’un exemple. Nous considérons un tirage à deux degrés selon des sondages aléatoires simples sans remise :\n\nun tirage d’un échantillon de \\(n_\\text{UP} =  1 000\\) unités primaires \\(S_\\text{UP}\\), réparties en cinq strates, parmi \\(N_\\text{UP} = 10 000\\) selon un plan aléatoire simple stratifié avec allocation proportionnelle,\nun tirage de \\(n_u = 4\\) unités secondaires parmi les \\(N_u = 10\\) unités secondaires dont chaque unité primaire \\(u\\) dispose. L’échantillon des unités secondaires obtenu est noté \\(S_\\text{US}\\). Un calage sur marges est ensuité réalisé au niveau des unités secondaires sur cinq variables quantitivatives \\(\\{ \\textbf{x}^\\text{cal}_k \\}_{k \\in S_ \\text{US}}\\) où pour tout \\(k\\), \\(\\textbf{x}^\\text{cal}_k = (\\textbf{x}^\\text{cal}_{k,1}, ..., \\textbf{x}^\\text{cal}_{k,5})\\) : la pondération calée est notée \\(\\{w^\\text{cal}_k\\}_{k \\in S_\\text{US}}\\). La méthode mobilisée est linéaire.\n\nLes données sont téléchargeables à l’adresse suivante.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLe fichier .Rdata contient trois tables info_ech, var_ech_cal, var_interet dont le contenu est décrit par les dictionnaires suivants :\n\n\n\n\n\n\n\nNom de la variable\nDéfinition\n\n\n\n\nid_psu\nIdentifiant de l’unité primaire.\n\n\nstrate_psu\nStrate de l’unité primaire.\n\n\nid_ssu\nIdentifiant de l’unité secondaire.\n\n\npi_psu\nProbabilité d’inclusion d’ordre 1 de l’unité primaire.\n\n\npi_ssu_cond_psu\nProbabilité d’inclusion d’ordre 1 de l’unité secondaire cond.aux unités primaires.\n\n\npoids_avant_calage\nPoids avant calage.\n\n\npoids_apres_calage\nPoids après calage.\n\n\n\n\n\n\nNom de la variable\nDéfinition\n\n\n\n\nid_psu\nIdentifiant de l’unité primaire.\n\n\nid_ssu\nIdentifiant de l’unité secondaire.\n\n\nvar_caln\nVariable de calage \\(n\\)\n\n\n\n\n\n\nNom de la variable\nDéfinition\n\n\n\n\nidentifiant\nIdentifiant de l’unité secondaire.\n\n\ny\nVariable d’intérêt \\(y\\)\n\n\nz\nVariable d’intérêt \\(z\\)\n\n\n\n\n\n\n\n\n\nObjectifs\n\n\n\nDans cet exercice, nous souhaitons produire deux estimateurs de variance basés sur deux variables d’intérêt \\(\\{y_k \\}_{k \\in S_\\text{US}}\\) et \\(\\{z_k \\}_{k \\in S_\\text{US}}\\) :\n\n\\(\\displaystyle \\widehat{\\mathbb{V}}(\\hat{t}_{z,\\text{cal}})\\), un estimateur de la variance de \\(\\displaystyle \\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}\\),\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\frac{\\hat{t}_{y,\\text{cal}}}{\\hat{t}_{z,\\text{cal}}})\\), un estimateur de la variance de \\(\\displaystyle \\frac{\\sum_{k \\in S_\\text{US}} y_k w_k^\\text{cal}}{\\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}}\\).\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\log({\\hat{t}_{z,\\text{cal}}}))\\), un estimateur de la variance de \\(\\displaystyle \\log({\\hat{t}_{z,\\text{cal}}})\\).\n\n\n\n\n\n\n\nAfin d’estimer la variance d’une statistique régulière, il est nécessaire de proposer un estimateur dans le cas simple de l’estimateur du total. Ce travail, réalisé par le méthodologue, consiste à utiliser des résultats théoriques et l’information sur la collecte (plan de sondage, redressements, …) afin d’approcher au mieux un estimateur sans biais de la variance.\nDans certains cas simples (cas d’un sondage aléatoire simple sans remise), il n’est pas nécessaire d’implémenter l’estimateur : des fonctions prêtes à l’emploi sont disponibles (fonction qvar par exemple).\nUn estimateur de la variance d’un estimateur du total d’Horvitz-Thompson \\(\\hat{t}_{y,\\text{HT}}\\) sous le plan de l’exemple est :\n\\[\n    \\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT}}) = \\sum_{\\text{st} = 1}^{n_\\text{st}} \\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}})\n\\]\noù \\[\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}}) = \\frac{N^2_{\\text{UP}\\cap \\text{st}}}{n_{\\text{UP}\\cap  \\text{st}}} \\left(1-\\underbrace{\\frac{n_{\\text{UP} \\cap \\text{st}}}{N_{\\text{UP}\\cap \\text{st}}}}_{= f_\\text{up}} \\right) s^2_{\\{\\hat{t}_{y,\\text{HT}, u}\\}_{u \\in S_\\text{UP} \\cap \\text{st}}} + \\frac{N_{\\text{UP}\\cap \\text{st}}}{n_{\\text{UP}\\cap \\text{st}}} \\left( \\sum_{u \\in S_\\text{UP} \\cap \\text{st}}  \\frac{N^2_u}{n_u} (1 - \\underbrace{\\frac{n_u}{N_u}}_{=f_u}) s^2_{\\{{y_k}\\}_{k \\in S_\\text{US}   \\cap u}}\\right) \\tag{1}\\]\noù pour tout \\(u\\in S_\\text{UP}\\), \\(\\displaystyle  \\hat{t}_{y,\\text{HT},u} = \\frac{N_u}{n_u}\\sum_{k \\in S_\\text{US} \\cap u} {y_k}\\) et \\(s^2_{\\{\\hat{t}_{y,\\text{HT}, u}\\}_{u \\in S_\\text{UP}}}\\) (resp. \\(s^2_{\\{y_k}\\}_{k \\in S_\\text{US}   \\cap u}\\)) désigne la dispersion de la variable \\(\\{{\\hat{t}_{y,\\text{HT}, u}}\\}_{u \\in S_\\text{UP}}\\) (resp. \\({\\{y_k\\}}_{k \\in S_\\text{US} \\cap u}\\)) sur l’échantillon \\(S_\\text{UP}\\) (resp. \\(S_\\text{US} \\cap u\\)).\n\n\n\n\n\n\nPreuve de l’expression de \\(\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}})\\)\n\n\n\n\n\nIl suffit d’appliquer la formule de Rao en utilisant l’estimateur de Sen-Yen-Grundy pour la variance d’un estimateur du total sous un plan aléatoire simple sans remise d’où \\(q_u = \\frac{N_{\\text{UP} \\cap \\text{st}}^2}{n_{\\text{UP} \\cap \\text{st}}^2} \\left( 1-f \\right)\\) et \\(\\pi_u^{(1)} = \\frac{n_{\\text{UP}}}{N_{\\text{UP}}}\\).\n\n\n\n\n\n\nUn estimateur de variance d’un estimateur calé peut être calculé en utilisant les résultats asymptotiques proposés par : un estimateur de la variance de l’estimateur \\(\\displaystyle \\sum_{k \\in S_\\text{US}} w^\\text{cal}_k y_k\\) dont la pondération est calée sur la variable \\(\\{  \\textbf{x}^\\text{cal}_k\\}_{k \\in S_\\text{US}}\\) est approximativement celle de l’estimateur d’Horvitz-Thompson des résidus \\(\\{\\varepsilon_k\\}_{k \\in S_\\text{US}}\\) de la régression pondérée (par les poids avant calage) de \\(\\{y_k\\}_{k \\in S_\\text{US}}\\) sur \\(\\{\\textbf{x}_k\\}_{k \\in S_\\text{US}}\\) estimée sur \\(S_\\text{US}\\).\nIl en vient que :\n\\[\n\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{cal}}) \\approx \\widehat{\\mathbb{V}}(\\hat{t}_{\\varepsilon,\\text{HT}})\n\\tag{2}\\]\n\n\n\nEn réunissant l’Equation 1 et l’Equation 2, il en vient que : \\[\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{cal}}) \\approx \\sum_{\\text{st} = 1}^{n_\\text{st}} \\widehat{\\mathbb{V}}(\\hat{t}_{\\varepsilon,\\text{HT},\\text{st}})\\]\n\n\n\n\n\n\nLa fonction calcul_var correspond à l’implémentation de l’estimateur construit précédemment.\nCet estimateur dépend de :\n\nla variable d’intérêt y,\ndes résidus de la régression de la variable y sur x,\nla fraction de sondage au premier degré f_up,\nla fraction de sondage au second degré f_us,\nla strate de chaque individu strate\n\nCes éléments seront donc des arguments de la fonction calcul_var.\n\n\n\nL’estimateur de variance proposé nécessite le calcul des résidus de la régression de la variable d’intérêt \\(\\{y_k\\}\\) sur les variables d’intérêt \\(\\{\\textbf{x}_k\\}\\). Ce calcul nécessite donc de connaître … la variable d’intérêt \\(\\{y_k\\}\\). Pour autant, certaines composantes peuvent être précalculées en amont.\nDans le cas des résidus de la régression de la variable d’intérêt \\(\\{y_k\\}\\) sur les variables d’intérêt \\(\\{\\textbf{x}_k\\}\\), il est possible de calculer l’inverse de la matrice \\(\\displaystyle \\sum_{k \\in S} \\frac{\\textbf{x}_k \\textbf{x}_k^T}{\\pi_k}\\) qui interviendra dans tous les calculs de résidus (et indépendamment de la variable \\(\\{\\textbf{x}_k\\}\\)).\ngustave permet de stocker ces informations dans un format consistant et de réutiliser ces informations facilement. Il s’agit des precalc\nComme vu durant la présentation, la fonction res_cal permet de récupérer les résidus :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSi la variable d’intérêt n’est pas disponible, il est possible de précalculer certains éléments entrants dans le calcul des résidus. Dans ce cas, il faudra renseigner NULL à l’argument y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLe résultat lorsque y est renseigné est de la même forme que y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPar contre, lorsque y = NULL, la fonction renvoie un precalc (formellement, il s’agit d’une liste). Cette liste contient les poids de sondage, la matrice des variables auxiliaires et l’inverse de la matrice de Gram inv.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nprecalc et argument id : permutation\n\n\n\nIl est recommandé de :\n\nfaire en sorte que y soit toujours une matrice (à une colonne dans notre cas univarié),\navoir des lignes nommées pour la matrice y et de renseigner l’argument id afin que gustave puisse vérifier au moment de l’application de la fonction res_cal si les valeurs renseignées dans le precalc et dans l’argument y sont dans le même ordre.\n\nSi ce n’est pas le cas, gustave renvoie une erreur.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nprecalc et absence d’argument id\n\n\n\nSi les lignes de la variable y ne sont pas nommées ou si l’argument id n’a pas été complété au moment de la définition du precalc alors aucune vérification ne pourra être réalisée.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nL’implémentation de l’estimateur peut-être décomposée en plusieurs étapes :\n\ncalcul des résidus à l’aide de la fonction gustave::res_cal,\ncalcul des estimations des totaux dans chaque unité primaire à l’aide de la fonction gustave::sum_by et de la fraction de sondage f_us\ncalcul de la variance de premier degré en utilisant la\ncalcul de la variance du second degré.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nConseil pour l’implémentation de la fonction calculant la variance\n\n\n\nIl est recommandé de construire la fonction calcul_var en faisant comme si y était une matrice (éventuellement à une colonne) : cela permettra de pouvoir estimer la variance de plusieurs fonctions d’intérêt plus rapidement.\n\n\n\n\n\nL’implémentation de l’estimateur passe par la définition d’un variance wrapper. Le variance wrapper contient toutes les informations nécessaires pour l’estimation. Il prend en argument une table contenant les variables d’intérêt ainsi qu’une expression décrivant un estimateur, un niveau pour les intervalles de confiance et renvoie une estimation de la variance associée à l’estimateur.\nLe variance wrapper est construit à l’aide de la fonction define_variance_wrapper en décrivant :\n\nla fonction de calcul de la variance (argument variance_function) : il s’agit d’une fonction prenant en argument une matrice \\(y\\) décrivant la variable d’intérêt \\(\\{y_k\\}_{k \\in S}\\) ainsi que d’autres informations permettant de proposer une estimation de la variance d’un estimateur du total,\nl’identifiant des individus (argument reference_id) : il s’agit d’un vecteur de même taille que le nombre de lignes de l’argument \\(\\textbf{y}\\) de la fonction renseignée dans l’argument variance_function indiquant l’ordre des identifiants des individus décrits,\nles poids utilisés pour l’estimation (argument reference_weight) : il s’agit d’un vecteur numérique contenant la pondération des individus. L’ordre des poids dans ce vecteur doit correspondre à celui des identifiants dans reference_id. Ces poids vont permettre à gustave de calculer l’estimation du paramètre d’intérêt,\nla liste des données utilisées par la fonction décrite dans l’argument variance_function (argument technical_data) : il s’agit d’une liste nommée contenant toutes les données nécessaires au calcul de la variance. Les noms des éléments de la liste doivent correspondre aux arguments de la fonction décrite dans variance_function excepté l’argument \\(y\\).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nUne fois le variance wrapper défini, l’utilisateur peut calculer des estimations de la variance d’estimateurs du total selon la méthode qu’il a choisi d’implémenter (argument variance_function lors de la définition du variance wrapper).\nPar exemple, pour estimer la variance de \\(\\displaystyle \\hat{t}_{y,\\text{cal}} = \\sum_{k \\in S} w_k^\\text{cal} y_k\\), il suffit d’utiliser la fonction precision_estim créée par define_variance_wrapper. Cette fonction contient un argument data correspondant à la table décrivant les informations sur la variable d’intérêt. L’utilisateur renseigne ensuite les estimateurs pour lesquels il souhaite une estimation de la variance à l’aide d’une expression. Dans l’exemple suivant, nous utilisons total(y) pour indiquer que nous souhaitons une estimation du total de la variable y de la table var_interet pondéré par les poids de calage.\n\n\nLa table contenant les variables d’intérêt (ici var_interet) doit contenir un identifiant dont le nom correspond à celui de l’argument default_id de la fonction define_variance_wrapper.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLes identifiants de la table var_interet ne semblent pas être dans le même ordre que ceux de la table info_ech.\nNous allons réaliser une première tentative en remettant les identifiants dans le même ordre.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTout se passe bien : aucun message d’avertissement ou d’erreur.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTable des variables d’intérêt non triée\n\n\n\nSi la variable identifiant de la table var_interet n’est pas triée dans le même ordre que le vecteur renseigné dans l’argument reference_id de define_variance_wrapper, le message d’avertissement suivant apparaîtra dans la console :\n The inputted id variable (id argument) appears not to match the reference id variable provided when the variance wrapper was defined: it is reordered and everything should be fine. Issues may nonetheless arise if part of the call is to be evaluated outside of the inputted data.frame (data argument).  \\(\\to\\) gustave remettra en ordre la table.\nPour autant, il est indiqué que dans certains cas, des comportements inattendus peuvent apparaître : il est donc recommandé de vérifier l’ordre de la table en intrant du variance wrapper.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTable des variables d’intérêt avec des observations supplémentaires\n\n\n\nSi la table var_interet contient des individus non renseignés dans le paramètre reference_id de la fonction define_variance_wrapper, ils seront retirés et le message d’avertissement suivant apparaîtra :\n xxx observations do not match any responding units of the survey. They are discarded \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTable des variables d’intérêt avec des observations manquantes\n\n\n\nSi certains individus renseignés dans le paramètre reference_id de la fonction define_variance_wrapper ne sont pas dans la table var_interet alors le message d’avertissement suivant apparaître : ~\\\n Some observations from the survey appear to be missing. The variance estimation function may produce unexpected results. \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nL’objectif de cet exercice est de proposer une estimation de :\n\n\\(\\displaystyle \\widehat{\\mathbb{V}}(\\hat{t}_{z,\\text{cal}})\\), un estimateur de la variance de \\(\\displaystyle \\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}\\),\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\frac{\\hat{t}_{y,\\text{cal}}}{\\hat{t}_{z,\\text{cal}}})\\), un estimateur de la variance de \\(\\displaystyle \\frac{\\sum_{k \\in S_\\text{US}} y_k w_k^\\text{cal}}{\\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}}\\).\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\log({\\hat{t}_{z,\\text{cal}}}))\\), un estimateur de la variance de \\(\\displaystyle \\log({\\hat{t}_{z,\\text{cal}}})\\).\n\nLes statistic wrapper permettent de calculer l’estimation de la fonction d’intérêt à partir des données de la table contenant les variables d’intérêt ainsi que dans la pondération renseignée dans l’argument reference_weight de la fonction variance wrapper. Ces fonctions permettent également de calculer les variables linéarisées estimées. La liste des statistic wrapper prédéfinis dans gustave est disponible ici :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIl est possible à l’utilisateur d’en ajouter en utilisant la fonction define_statistic_wrapper.\n\n\nDans ce premier cas, il s’agit d’estimer la variance du total d’un estimateur calé. Cette estimation correspond au cas implémenté directement dans la fonction calcul_var renseignée dans l’argument variance_function de la fonction define_variance_wrapper. Nous n’avons pas besoin ici de linéariser la fonction d’intérêt considérée (Il est assez immédiat de montrer que si la linéarisation par développement de Taylor était utilisée ici alors on retrouverait la variable d’intérêt comme variable linéarisée estimée).\nDans le cas du total, il n’est pas nécessaire d’indiquer le statistic wrapper total. Pour autant, pour plus de lisibilité, il est recommandé de toujours indiquer la fonction.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPour l’estimation de la variance de \\(\\frac{\\hat{t}_{y,\\text{cal}}}{\\hat{t}_{z,\\text{cal}}}\\), il est nécessaire d’avoir recours au principe de linéarisation. Parmi les statistic wrapper prédéfinis dans gustave, il y a la fonction ratio. Cette dernière va être mobilisée lors de l’appel au variance wrapper precision_estim\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nComme dans le cas précédent, il va être nécessaire d’utiliser le principe de linéarisation. Néanmoins, il n’existe pas de statistic wrapper dans gustave correspondant à la fonction inverse. Nous allons le construire à l’aide de la fonction define_statistic_wrapper. Avant cela, il est nécessaire de calculer la variable linéarisée estimée.\nLa variable linéarisée estimée est \\(\\widehat{u_k} = \\frac{z_k}{\\hat{t}_{z,\\text{cal}}}\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nIl est possible de vérifier la qualité des estimateurs à l’aide de simulations. En effet, ici, les variables d’intérêt sont connues pour tous les individus de la population : nous pouvons donc tirer de nouveaux échantillons et appliquer l’intégralité des redressements pour avoir de nouvelles réalisations des estimateurs calés \\(\\hat{t}_{y,\\text{cal}}\\) et \\(\\hat{t}_{z,\\text{cal}}\\). En pratique, nous ne pouvons utiliser cette méthode directement sur les variables d’intérêt car elles ne sont connues que sur l’échantillon.\n\n\n\n\n\n\nCode pour estimer, par simulation, la variance des estimateurs considérés\n\n\n\n\n\nCe code permet d’obtenir des réalisations des estimateurs \\(\\hat{t}_{y,\\text{cal}}\\) et \\(\\hat{t}_{z,\\text{cal}}\\). Un estimateur, basé sur \\(N_\\text{sim}\\) simulations, de la variance de \\(f(\\hat{t}_{y,\\text{cal}}, \\hat{t}_{z,\\text{cal}})\\) peut s’obtenir en calculant la dispersion des \\(N_\\text{sim}\\) réalisations de \\(f(\\hat{t}_{y,\\text{cal}}, \\hat{t}_{z,\\text{cal}})\\).\nLe code ci-après n’est pas optimal.\n\n#Données pour colloque\n\n#install.packages(\"icarus\")\n\nlibrary(\"icarus\")\nlibrary(\"data.table\")\n\n\nset.seed(2404)\n\n\nN_psu &lt;- 10000 #\nn_psu &lt;- 1000\nnb_strate_psu &lt;- 5 #number of strates in PSU population\nnom_strate_psu &lt;- LETTERS[1:nb_strate_psu]\nnb_var_cal &lt;- 5\nnb_ssu_per_psu &lt;- 10 #number of ssu in each PSU\nN_ssu &lt;- N_psu * nb_ssu_per_psu #number of ssu in the whole population\nn_ssu_per_psu &lt;- 4 #ssu sample size in each psu\n\n#Génération des variables selon une loi normale\nvar_cal &lt;- matrix(rnorm(nb_var_cal*N_ssu), ncol = nb_var_cal)\nvar_cal &lt;- data.table(var_cal)\ncolnames(var_cal) &lt;- paste0(\"var_cal\", 1:nb_var_cal)\n\n#Génération des strates\nstrate_psu &lt;- sample(nom_strate_psu, N_psu, replace = TRUE)\n#La table pop_data contient les informations sur l'ensemble de la population.\n#On échantillonnera dedans\npop_data &lt;- data.table(\"id_psu\" = paste0(\"psu\", 1:N_psu),\n                       \"strate_psu\" = strate_psu)\nlink_psu_ssu &lt;- data.table(\"id_psu\" = rep(pop_data$id, each = 10),\n                           \"id_ssu\" = paste0(\"ssu\", 1:N_ssu))\n\n\npop_data&lt;- merge(pop_data,\n                 link_psu_ssu,\n                 by = \"id_psu\")\npop_data$id_ssu &lt;- paste0(\"ssu\", 1:N_ssu)\npop_data &lt;- cbind(pop_data, var_cal)\n\n\n#Variable d'intérêt 1/2\npop_data$y &lt;- 100 + as.matrix(var_cal) %*% c(0.2,0.3,0.5,0.1,5) + 30*(pop_data$strate_psu == \"A\") + \n  15*((pop_data$strate_psu %in% c(\"B\",\"C\"))) + 3*(!(pop_data$strate_psu %in% c(\"A\",\"B\",\"C\")))\n#pop_data$z &lt;- 3 + sqrt(pop_data$y) + rnorm(nrow(pop_data), 0, 1)\npop_data$z &lt;- 3 + 2*pop_data$var_cal2 - pop_data$var_cal1*pop_data$var_cal4 + rnorm(nrow(pop_data), 0, 1)\nboxplot(pop_data$y ~ pop_data$strate_psu) #On a bien des comportements différents selon la strate\nboxplot(pop_data$z ~ pop_data$strate_psu) #On a bien des comportements différents selon la strate\n\n#Calcul des marges\nmarges &lt;- colSums(pop_data[, paste0(\"var_cal\",1:nb_var_cal), with = F])\n###Mise au format icarus\nmarges_table &lt;- cbind(names(marges), \"0\", marges)\n\n\n###############################\n#####Echantillonnage###########\n###############################\n#SASSR(10%) dans chaque strate de psu\n#SASSR(4) au sein de chaque psu\n\n\nrm(list = setdiff(ls(), c(\"pop_data\",\"n_psu\",\"nb_strate_psu\",\n                          \"n_ssu_per_psu\", \"N_psu\", \"nb_ssu_per_psu\",\n                          \"marges_table\")))\n\n\n\ntirage &lt;- function(pop_data, n_psu, N_psu,  nb_strate_psu, n_ssu_per_psu, nb_ssu_per_psu){\n  #Population of PSU\n  sample_psu &lt;- unique(pop_data[, .(strate_psu, id_psu)])\n  #Tirage selon une loi uniforme\n  sample_psu$tirage_psu &lt;- runif(nrow(sample_psu))\n  #Tri selon les réalisations\n  setorder(sample_psu, tirage_psu)\n  #Tirage des psu\n  sample_psu &lt;- sample_psu[,lapply(.SD, function(x){head(unique(x), n = as.integer(n_psu/nb_strate_psu))}), by = strate_psu]\n  sample_psu_id &lt;- sample_psu[, id_psu]\n  \n  #Tirage des ssu\n  sample_ssu &lt;- unique(pop_data[id_psu %in% sample_psu_id, .(id_psu, id_ssu)])\n  sample_ssu$tirage_ssu &lt;- runif(nrow(sample_ssu))\n  setorder(sample_ssu, tirage_ssu)\n  sample_ssu &lt;- sample_ssu[,lapply(.SD, function(x){head(unique(x), n = n_ssu_per_psu)}), by = id_psu]\n  sample_ssu_id &lt;- sample_ssu[, id_ssu]\n  \n  #Ajout d'informations dans la table echantillon\n  echantillon &lt;- pop_data[id_ssu %in% sample_ssu_id]\n  echantillon$pi_psu &lt;- n_psu/N_psu\n  echantillon$pi_ssu_cond_psu &lt;- n_ssu_per_psu/nb_ssu_per_psu\n  echantillon[, poids_avant_calage := 1/(pi_psu*pi_ssu_cond_psu)]\n  echantillon[, eff := 1]\n  \n  #Calage\n  echantillon$poids_apres_calage &lt;- calibration(echantillon,\n                                                marginMatrix = marges_table,\n                                                colWeights = \"poids_avant_calage\",\n                                                description = FALSE)\n  \n  return(echantillon)\n}\n\n\nsimulation &lt;- function(pop_data, \n                       n_psu, \n                       N_psu,\n                       nb_strate_psu, \n                       n_ssu_per_psu,\n                       nb_ssu_per_psu,\n                       nb_sim = 1000L){\n  res &lt;- list()\n  for(i in 1:nb_sim){\n    donnees &lt;- tirage(pop_data, \n                      n_psu, \n                      N_psu,\n                      nb_strate_psu, \n                      n_ssu_per_psu,\n                      nb_ssu_per_psu)\n    res[[i]] &lt;- c(\"v1\" = sum(donnees$z * donnees$poids_apres_calage),\n                  \"v11\" = sum(donnees$z * donnees$poids_avant_calage),\n                  \"v2\" = sum(donnees$y * donnees$poids_apres_calage)/sum(donnees$z * donnees$poids_apres_calage),\n                  \"v21\" = sum(donnees$y * donnees$poids_avant_calage)/sum(donnees$z * donnees$poids_avant_calage),\n                  \"v4\" = log(sum(donnees$z * donnees$poids_apres_calage)),\n                  \"v41\" = log(sum(donnees$z * donnees$poids_avant_calage))\n    )\n    \n  }\n  return(res)\n}\n\n\nres_var &lt;- simulation(pop_data, \n                      n_psu, \n                      N_psu,\n                      nb_strate_psu, \n                      n_ssu_per_psu,\n                      nb_ssu_per_psu,\n                      nb_sim = 10000L)\n\n\nres_sim &lt;- Reduce(rbind, res_var)\nres_sim_mean &lt;- apply(X = res, 2, var)\nres_sim_var &lt;- apply(X = res, 2, var)\n\n\n\n\nLes résultats obtenus après \\(N_\\text{sim} = 10~000\\) simulations sont :\n\n\n\n\nEstimation de l’espérance\n\n\n\n\n\nEstimation 1\n\n\nEstimation 2\n\n\nEstimation 3\n\n\n\n\n1\n\n\n2.997E+05\n\n\n3.773E+01\n\n\n1.261E+01\n\n\n\n\n\n\nEstimation de la variance\n\n\n\n\n\nEstimation 1\n\n\nEstimation 2\n\n\nEstimation 3\n\n\n\n\n1\n\n\n4.969E+06\n\n\n7.786E-02\n\n\n5.531E-05\n\n\n\n\n\n\n\n\n\nLe variance wrapper contient toute l’information nécessaire au calcul de précision : cela passe par les données de calage, les données utilisées pour certains plans de sondage, … Ces données peuvent présenter un enjeu de confidentialité en exposant ces données.\nPrenons l’exemple d’un utilisateur ne disposant que du variance wrapper precision_estim.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLorsqu’un utilisateur affiche le contenu de la fonction precision_estim, il ne voit pas les données associées.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOuf ? Pas de problème donc … ? Non, lorsqu’un utilsateur considère l’environnement associé au variance wrapper, il est possible de retrouver les données.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOn peut, par exemple, afficher les variables de calage :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/var_gustave.html#etape-1-estimateur-de-la-variance-dun-estimateur-calé-du-total",
    "href": "presentations/var_gustave.html#etape-1-estimateur-de-la-variance-dun-estimateur-calé-du-total",
    "title": "Estimation de variance analytique avec gustave",
    "section": "",
    "text": "Afin d’estimer la variance d’une statistique régulière, il est nécessaire de proposer un estimateur dans le cas simple de l’estimateur du total. Ce travail, réalisé par le méthodologue, consiste à utiliser des résultats théoriques et l’information sur la collecte (plan de sondage, redressements, …) afin d’approcher au mieux un estimateur sans biais de la variance.\nDans certains cas simples (cas d’un sondage aléatoire simple sans remise), il n’est pas nécessaire d’implémenter l’estimateur : des fonctions prêtes à l’emploi sont disponibles (fonction qvar par exemple).\nUn estimateur de la variance d’un estimateur du total d’Horvitz-Thompson \\(\\hat{t}_{y,\\text{HT}}\\) sous le plan de l’exemple est :\n\\[\n    \\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT}}) = \\sum_{\\text{st} = 1}^{n_\\text{st}} \\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}})\n\\]\noù \\[\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}}) = \\frac{N^2_{\\text{UP}\\cap \\text{st}}}{n_{\\text{UP}\\cap  \\text{st}}} \\left(1-\\underbrace{\\frac{n_{\\text{UP} \\cap \\text{st}}}{N_{\\text{UP}\\cap \\text{st}}}}_{= f_\\text{up}} \\right) s^2_{\\{\\hat{t}_{y,\\text{HT}, u}\\}_{u \\in S_\\text{UP} \\cap \\text{st}}} + \\frac{N_{\\text{UP}\\cap \\text{st}}}{n_{\\text{UP}\\cap \\text{st}}} \\left( \\sum_{u \\in S_\\text{UP} \\cap \\text{st}}  \\frac{N^2_u}{n_u} (1 - \\underbrace{\\frac{n_u}{N_u}}_{=f_u}) s^2_{\\{{y_k}\\}_{k \\in S_\\text{US}   \\cap u}}\\right) \\tag{1}\\]\noù pour tout \\(u\\in S_\\text{UP}\\), \\(\\displaystyle  \\hat{t}_{y,\\text{HT},u} = \\frac{N_u}{n_u}\\sum_{k \\in S_\\text{US} \\cap u} {y_k}\\) et \\(s^2_{\\{\\hat{t}_{y,\\text{HT}, u}\\}_{u \\in S_\\text{UP}}}\\) (resp. \\(s^2_{\\{y_k}\\}_{k \\in S_\\text{US}   \\cap u}\\)) désigne la dispersion de la variable \\(\\{{\\hat{t}_{y,\\text{HT}, u}}\\}_{u \\in S_\\text{UP}}\\) (resp. \\({\\{y_k\\}}_{k \\in S_\\text{US} \\cap u}\\)) sur l’échantillon \\(S_\\text{UP}\\) (resp. \\(S_\\text{US} \\cap u\\)).\n\n\n\n\n\n\nPreuve de l’expression de \\(\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{HT},\\text{st}})\\)\n\n\n\n\n\nIl suffit d’appliquer la formule de Rao en utilisant l’estimateur de Sen-Yen-Grundy pour la variance d’un estimateur du total sous un plan aléatoire simple sans remise d’où \\(q_u = \\frac{N_{\\text{UP} \\cap \\text{st}}^2}{n_{\\text{UP} \\cap \\text{st}}^2} \\left( 1-f \\right)\\) et \\(\\pi_u^{(1)} = \\frac{n_{\\text{UP}}}{N_{\\text{UP}}}\\).\n\n\n\n\n\n\nUn estimateur de variance d’un estimateur calé peut être calculé en utilisant les résultats asymptotiques proposés par : un estimateur de la variance de l’estimateur \\(\\displaystyle \\sum_{k \\in S_\\text{US}} w^\\text{cal}_k y_k\\) dont la pondération est calée sur la variable \\(\\{  \\textbf{x}^\\text{cal}_k\\}_{k \\in S_\\text{US}}\\) est approximativement celle de l’estimateur d’Horvitz-Thompson des résidus \\(\\{\\varepsilon_k\\}_{k \\in S_\\text{US}}\\) de la régression pondérée (par les poids avant calage) de \\(\\{y_k\\}_{k \\in S_\\text{US}}\\) sur \\(\\{\\textbf{x}_k\\}_{k \\in S_\\text{US}}\\) estimée sur \\(S_\\text{US}\\).\nIl en vient que :\n\\[\n\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{cal}}) \\approx \\widehat{\\mathbb{V}}(\\hat{t}_{\\varepsilon,\\text{HT}})\n\\tag{2}\\]\n\n\n\nEn réunissant l’Equation 1 et l’Equation 2, il en vient que : \\[\\widehat{\\mathbb{V}}(\\hat{t}_{y,\\text{cal}}) \\approx \\sum_{\\text{st} = 1}^{n_\\text{st}} \\widehat{\\mathbb{V}}(\\hat{t}_{\\varepsilon,\\text{HT},\\text{st}})\\]"
  },
  {
    "objectID": "presentations/var_gustave.html#etape-2-implémentation",
    "href": "presentations/var_gustave.html#etape-2-implémentation",
    "title": "Estimation de variance analytique avec gustave",
    "section": "",
    "text": "La fonction calcul_var correspond à l’implémentation de l’estimateur construit précédemment.\nCet estimateur dépend de :\n\nla variable d’intérêt y,\ndes résidus de la régression de la variable y sur x,\nla fraction de sondage au premier degré f_up,\nla fraction de sondage au second degré f_us,\nla strate de chaque individu strate\n\nCes éléments seront donc des arguments de la fonction calcul_var.\n\n\n\nL’estimateur de variance proposé nécessite le calcul des résidus de la régression de la variable d’intérêt \\(\\{y_k\\}\\) sur les variables d’intérêt \\(\\{\\textbf{x}_k\\}\\). Ce calcul nécessite donc de connaître … la variable d’intérêt \\(\\{y_k\\}\\). Pour autant, certaines composantes peuvent être précalculées en amont.\nDans le cas des résidus de la régression de la variable d’intérêt \\(\\{y_k\\}\\) sur les variables d’intérêt \\(\\{\\textbf{x}_k\\}\\), il est possible de calculer l’inverse de la matrice \\(\\displaystyle \\sum_{k \\in S} \\frac{\\textbf{x}_k \\textbf{x}_k^T}{\\pi_k}\\) qui interviendra dans tous les calculs de résidus (et indépendamment de la variable \\(\\{\\textbf{x}_k\\}\\)).\ngustave permet de stocker ces informations dans un format consistant et de réutiliser ces informations facilement. Il s’agit des precalc\nComme vu durant la présentation, la fonction res_cal permet de récupérer les résidus :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSi la variable d’intérêt n’est pas disponible, il est possible de précalculer certains éléments entrants dans le calcul des résidus. Dans ce cas, il faudra renseigner NULL à l’argument y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLe résultat lorsque y est renseigné est de la même forme que y.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nPar contre, lorsque y = NULL, la fonction renvoie un precalc (formellement, il s’agit d’une liste). Cette liste contient les poids de sondage, la matrice des variables auxiliaires et l’inverse de la matrice de Gram inv.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nprecalc et argument id : permutation\n\n\n\nIl est recommandé de :\n\nfaire en sorte que y soit toujours une matrice (à une colonne dans notre cas univarié),\navoir des lignes nommées pour la matrice y et de renseigner l’argument id afin que gustave puisse vérifier au moment de l’application de la fonction res_cal si les valeurs renseignées dans le precalc et dans l’argument y sont dans le même ordre.\n\nSi ce n’est pas le cas, gustave renvoie une erreur.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nprecalc et absence d’argument id\n\n\n\nSi les lignes de la variable y ne sont pas nommées ou si l’argument id n’a pas été complété au moment de la définition du precalc alors aucune vérification ne pourra être réalisée.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nL’implémentation de l’estimateur peut-être décomposée en plusieurs étapes :\n\ncalcul des résidus à l’aide de la fonction gustave::res_cal,\ncalcul des estimations des totaux dans chaque unité primaire à l’aide de la fonction gustave::sum_by et de la fraction de sondage f_us\ncalcul de la variance de premier degré en utilisant la\ncalcul de la variance du second degré.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nConseil pour l’implémentation de la fonction calculant la variance\n\n\n\nIl est recommandé de construire la fonction calcul_var en faisant comme si y était une matrice (éventuellement à une colonne) : cela permettra de pouvoir estimer la variance de plusieurs fonctions d’intérêt plus rapidement.\n\n\n\n\n\nL’implémentation de l’estimateur passe par la définition d’un variance wrapper. Le variance wrapper contient toutes les informations nécessaires pour l’estimation. Il prend en argument une table contenant les variables d’intérêt ainsi qu’une expression décrivant un estimateur, un niveau pour les intervalles de confiance et renvoie une estimation de la variance associée à l’estimateur.\nLe variance wrapper est construit à l’aide de la fonction define_variance_wrapper en décrivant :\n\nla fonction de calcul de la variance (argument variance_function) : il s’agit d’une fonction prenant en argument une matrice \\(y\\) décrivant la variable d’intérêt \\(\\{y_k\\}_{k \\in S}\\) ainsi que d’autres informations permettant de proposer une estimation de la variance d’un estimateur du total,\nl’identifiant des individus (argument reference_id) : il s’agit d’un vecteur de même taille que le nombre de lignes de l’argument \\(\\textbf{y}\\) de la fonction renseignée dans l’argument variance_function indiquant l’ordre des identifiants des individus décrits,\nles poids utilisés pour l’estimation (argument reference_weight) : il s’agit d’un vecteur numérique contenant la pondération des individus. L’ordre des poids dans ce vecteur doit correspondre à celui des identifiants dans reference_id. Ces poids vont permettre à gustave de calculer l’estimation du paramètre d’intérêt,\nla liste des données utilisées par la fonction décrite dans l’argument variance_function (argument technical_data) : il s’agit d’une liste nommée contenant toutes les données nécessaires au calcul de la variance. Les noms des éléments de la liste doivent correspondre aux arguments de la fonction décrite dans variance_function excepté l’argument \\(y\\).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "presentations/var_gustave.html#etape-3-utilisation-et-diffusion",
    "href": "presentations/var_gustave.html#etape-3-utilisation-et-diffusion",
    "title": "Estimation de variance analytique avec gustave",
    "section": "",
    "text": "Une fois le variance wrapper défini, l’utilisateur peut calculer des estimations de la variance d’estimateurs du total selon la méthode qu’il a choisi d’implémenter (argument variance_function lors de la définition du variance wrapper).\nPar exemple, pour estimer la variance de \\(\\displaystyle \\hat{t}_{y,\\text{cal}} = \\sum_{k \\in S} w_k^\\text{cal} y_k\\), il suffit d’utiliser la fonction precision_estim créée par define_variance_wrapper. Cette fonction contient un argument data correspondant à la table décrivant les informations sur la variable d’intérêt. L’utilisateur renseigne ensuite les estimateurs pour lesquels il souhaite une estimation de la variance à l’aide d’une expression. Dans l’exemple suivant, nous utilisons total(y) pour indiquer que nous souhaitons une estimation du total de la variable y de la table var_interet pondéré par les poids de calage.\n\n\nLa table contenant les variables d’intérêt (ici var_interet) doit contenir un identifiant dont le nom correspond à celui de l’argument default_id de la fonction define_variance_wrapper.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLes identifiants de la table var_interet ne semblent pas être dans le même ordre que ceux de la table info_ech.\nNous allons réaliser une première tentative en remettant les identifiants dans le même ordre.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTout se passe bien : aucun message d’avertissement ou d’erreur.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTable des variables d’intérêt non triée\n\n\n\nSi la variable identifiant de la table var_interet n’est pas triée dans le même ordre que le vecteur renseigné dans l’argument reference_id de define_variance_wrapper, le message d’avertissement suivant apparaîtra dans la console :\n The inputted id variable (id argument) appears not to match the reference id variable provided when the variance wrapper was defined: it is reordered and everything should be fine. Issues may nonetheless arise if part of the call is to be evaluated outside of the inputted data.frame (data argument).  \\(\\to\\) gustave remettra en ordre la table.\nPour autant, il est indiqué que dans certains cas, des comportements inattendus peuvent apparaître : il est donc recommandé de vérifier l’ordre de la table en intrant du variance wrapper.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTable des variables d’intérêt avec des observations supplémentaires\n\n\n\nSi la table var_interet contient des individus non renseignés dans le paramètre reference_id de la fonction define_variance_wrapper, ils seront retirés et le message d’avertissement suivant apparaîtra :\n xxx observations do not match any responding units of the survey. They are discarded \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nTable des variables d’intérêt avec des observations manquantes\n\n\n\nSi certains individus renseignés dans le paramètre reference_id de la fonction define_variance_wrapper ne sont pas dans la table var_interet alors le message d’avertissement suivant apparaître : ~\\\n Some observations from the survey appear to be missing. The variance estimation function may produce unexpected results. \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nL’objectif de cet exercice est de proposer une estimation de :\n\n\\(\\displaystyle \\widehat{\\mathbb{V}}(\\hat{t}_{z,\\text{cal}})\\), un estimateur de la variance de \\(\\displaystyle \\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}\\),\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\frac{\\hat{t}_{y,\\text{cal}}}{\\hat{t}_{z,\\text{cal}}})\\), un estimateur de la variance de \\(\\displaystyle \\frac{\\sum_{k \\in S_\\text{US}} y_k w_k^\\text{cal}}{\\sum_{k \\in S_\\text{US}} z_k w_k^\\text{cal}}\\).\n\\(\\displaystyle  \\widehat{\\mathbb{V}}(\\log({\\hat{t}_{z,\\text{cal}}}))\\), un estimateur de la variance de \\(\\displaystyle \\log({\\hat{t}_{z,\\text{cal}}})\\).\n\nLes statistic wrapper permettent de calculer l’estimation de la fonction d’intérêt à partir des données de la table contenant les variables d’intérêt ainsi que dans la pondération renseignée dans l’argument reference_weight de la fonction variance wrapper. Ces fonctions permettent également de calculer les variables linéarisées estimées. La liste des statistic wrapper prédéfinis dans gustave est disponible ici :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIl est possible à l’utilisateur d’en ajouter en utilisant la fonction define_statistic_wrapper.\n\n\nDans ce premier cas, il s’agit d’estimer la variance du total d’un estimateur calé. Cette estimation correspond au cas implémenté directement dans la fonction calcul_var renseignée dans l’argument variance_function de la fonction define_variance_wrapper. Nous n’avons pas besoin ici de linéariser la fonction d’intérêt considérée (Il est assez immédiat de montrer que si la linéarisation par développement de Taylor était utilisée ici alors on retrouverait la variable d’intérêt comme variable linéarisée estimée).\nDans le cas du total, il n’est pas nécessaire d’indiquer le statistic wrapper total. Pour autant, pour plus de lisibilité, il est recommandé de toujours indiquer la fonction.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPour l’estimation de la variance de \\(\\frac{\\hat{t}_{y,\\text{cal}}}{\\hat{t}_{z,\\text{cal}}}\\), il est nécessaire d’avoir recours au principe de linéarisation. Parmi les statistic wrapper prédéfinis dans gustave, il y a la fonction ratio. Cette dernière va être mobilisée lors de l’appel au variance wrapper precision_estim\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nComme dans le cas précédent, il va être nécessaire d’utiliser le principe de linéarisation. Néanmoins, il n’existe pas de statistic wrapper dans gustave correspondant à la fonction inverse. Nous allons le construire à l’aide de la fonction define_statistic_wrapper. Avant cela, il est nécessaire de calculer la variable linéarisée estimée.\nLa variable linéarisée estimée est \\(\\widehat{u_k} = \\frac{z_k}{\\hat{t}_{z,\\text{cal}}}\\).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nIl est possible de vérifier la qualité des estimateurs à l’aide de simulations. En effet, ici, les variables d’intérêt sont connues pour tous les individus de la population : nous pouvons donc tirer de nouveaux échantillons et appliquer l’intégralité des redressements pour avoir de nouvelles réalisations des estimateurs calés \\(\\hat{t}_{y,\\text{cal}}\\) et \\(\\hat{t}_{z,\\text{cal}}\\). En pratique, nous ne pouvons utiliser cette méthode directement sur les variables d’intérêt car elles ne sont connues que sur l’échantillon.\n\n\n\n\n\n\nCode pour estimer, par simulation, la variance des estimateurs considérés\n\n\n\n\n\nCe code permet d’obtenir des réalisations des estimateurs \\(\\hat{t}_{y,\\text{cal}}\\) et \\(\\hat{t}_{z,\\text{cal}}\\). Un estimateur, basé sur \\(N_\\text{sim}\\) simulations, de la variance de \\(f(\\hat{t}_{y,\\text{cal}}, \\hat{t}_{z,\\text{cal}})\\) peut s’obtenir en calculant la dispersion des \\(N_\\text{sim}\\) réalisations de \\(f(\\hat{t}_{y,\\text{cal}}, \\hat{t}_{z,\\text{cal}})\\).\nLe code ci-après n’est pas optimal.\n\n#Données pour colloque\n\n#install.packages(\"icarus\")\n\nlibrary(\"icarus\")\nlibrary(\"data.table\")\n\n\nset.seed(2404)\n\n\nN_psu &lt;- 10000 #\nn_psu &lt;- 1000\nnb_strate_psu &lt;- 5 #number of strates in PSU population\nnom_strate_psu &lt;- LETTERS[1:nb_strate_psu]\nnb_var_cal &lt;- 5\nnb_ssu_per_psu &lt;- 10 #number of ssu in each PSU\nN_ssu &lt;- N_psu * nb_ssu_per_psu #number of ssu in the whole population\nn_ssu_per_psu &lt;- 4 #ssu sample size in each psu\n\n#Génération des variables selon une loi normale\nvar_cal &lt;- matrix(rnorm(nb_var_cal*N_ssu), ncol = nb_var_cal)\nvar_cal &lt;- data.table(var_cal)\ncolnames(var_cal) &lt;- paste0(\"var_cal\", 1:nb_var_cal)\n\n#Génération des strates\nstrate_psu &lt;- sample(nom_strate_psu, N_psu, replace = TRUE)\n#La table pop_data contient les informations sur l'ensemble de la population.\n#On échantillonnera dedans\npop_data &lt;- data.table(\"id_psu\" = paste0(\"psu\", 1:N_psu),\n                       \"strate_psu\" = strate_psu)\nlink_psu_ssu &lt;- data.table(\"id_psu\" = rep(pop_data$id, each = 10),\n                           \"id_ssu\" = paste0(\"ssu\", 1:N_ssu))\n\n\npop_data&lt;- merge(pop_data,\n                 link_psu_ssu,\n                 by = \"id_psu\")\npop_data$id_ssu &lt;- paste0(\"ssu\", 1:N_ssu)\npop_data &lt;- cbind(pop_data, var_cal)\n\n\n#Variable d'intérêt 1/2\npop_data$y &lt;- 100 + as.matrix(var_cal) %*% c(0.2,0.3,0.5,0.1,5) + 30*(pop_data$strate_psu == \"A\") + \n  15*((pop_data$strate_psu %in% c(\"B\",\"C\"))) + 3*(!(pop_data$strate_psu %in% c(\"A\",\"B\",\"C\")))\n#pop_data$z &lt;- 3 + sqrt(pop_data$y) + rnorm(nrow(pop_data), 0, 1)\npop_data$z &lt;- 3 + 2*pop_data$var_cal2 - pop_data$var_cal1*pop_data$var_cal4 + rnorm(nrow(pop_data), 0, 1)\nboxplot(pop_data$y ~ pop_data$strate_psu) #On a bien des comportements différents selon la strate\nboxplot(pop_data$z ~ pop_data$strate_psu) #On a bien des comportements différents selon la strate\n\n#Calcul des marges\nmarges &lt;- colSums(pop_data[, paste0(\"var_cal\",1:nb_var_cal), with = F])\n###Mise au format icarus\nmarges_table &lt;- cbind(names(marges), \"0\", marges)\n\n\n###############################\n#####Echantillonnage###########\n###############################\n#SASSR(10%) dans chaque strate de psu\n#SASSR(4) au sein de chaque psu\n\n\nrm(list = setdiff(ls(), c(\"pop_data\",\"n_psu\",\"nb_strate_psu\",\n                          \"n_ssu_per_psu\", \"N_psu\", \"nb_ssu_per_psu\",\n                          \"marges_table\")))\n\n\n\ntirage &lt;- function(pop_data, n_psu, N_psu,  nb_strate_psu, n_ssu_per_psu, nb_ssu_per_psu){\n  #Population of PSU\n  sample_psu &lt;- unique(pop_data[, .(strate_psu, id_psu)])\n  #Tirage selon une loi uniforme\n  sample_psu$tirage_psu &lt;- runif(nrow(sample_psu))\n  #Tri selon les réalisations\n  setorder(sample_psu, tirage_psu)\n  #Tirage des psu\n  sample_psu &lt;- sample_psu[,lapply(.SD, function(x){head(unique(x), n = as.integer(n_psu/nb_strate_psu))}), by = strate_psu]\n  sample_psu_id &lt;- sample_psu[, id_psu]\n  \n  #Tirage des ssu\n  sample_ssu &lt;- unique(pop_data[id_psu %in% sample_psu_id, .(id_psu, id_ssu)])\n  sample_ssu$tirage_ssu &lt;- runif(nrow(sample_ssu))\n  setorder(sample_ssu, tirage_ssu)\n  sample_ssu &lt;- sample_ssu[,lapply(.SD, function(x){head(unique(x), n = n_ssu_per_psu)}), by = id_psu]\n  sample_ssu_id &lt;- sample_ssu[, id_ssu]\n  \n  #Ajout d'informations dans la table echantillon\n  echantillon &lt;- pop_data[id_ssu %in% sample_ssu_id]\n  echantillon$pi_psu &lt;- n_psu/N_psu\n  echantillon$pi_ssu_cond_psu &lt;- n_ssu_per_psu/nb_ssu_per_psu\n  echantillon[, poids_avant_calage := 1/(pi_psu*pi_ssu_cond_psu)]\n  echantillon[, eff := 1]\n  \n  #Calage\n  echantillon$poids_apres_calage &lt;- calibration(echantillon,\n                                                marginMatrix = marges_table,\n                                                colWeights = \"poids_avant_calage\",\n                                                description = FALSE)\n  \n  return(echantillon)\n}\n\n\nsimulation &lt;- function(pop_data, \n                       n_psu, \n                       N_psu,\n                       nb_strate_psu, \n                       n_ssu_per_psu,\n                       nb_ssu_per_psu,\n                       nb_sim = 1000L){\n  res &lt;- list()\n  for(i in 1:nb_sim){\n    donnees &lt;- tirage(pop_data, \n                      n_psu, \n                      N_psu,\n                      nb_strate_psu, \n                      n_ssu_per_psu,\n                      nb_ssu_per_psu)\n    res[[i]] &lt;- c(\"v1\" = sum(donnees$z * donnees$poids_apres_calage),\n                  \"v11\" = sum(donnees$z * donnees$poids_avant_calage),\n                  \"v2\" = sum(donnees$y * donnees$poids_apres_calage)/sum(donnees$z * donnees$poids_apres_calage),\n                  \"v21\" = sum(donnees$y * donnees$poids_avant_calage)/sum(donnees$z * donnees$poids_avant_calage),\n                  \"v4\" = log(sum(donnees$z * donnees$poids_apres_calage)),\n                  \"v41\" = log(sum(donnees$z * donnees$poids_avant_calage))\n    )\n    \n  }\n  return(res)\n}\n\n\nres_var &lt;- simulation(pop_data, \n                      n_psu, \n                      N_psu,\n                      nb_strate_psu, \n                      n_ssu_per_psu,\n                      nb_ssu_per_psu,\n                      nb_sim = 10000L)\n\n\nres_sim &lt;- Reduce(rbind, res_var)\nres_sim_mean &lt;- apply(X = res, 2, var)\nres_sim_var &lt;- apply(X = res, 2, var)\n\n\n\n\nLes résultats obtenus après \\(N_\\text{sim} = 10~000\\) simulations sont :\n\n\n\n\nEstimation de l’espérance\n\n\n\n\n\nEstimation 1\n\n\nEstimation 2\n\n\nEstimation 3\n\n\n\n\n1\n\n\n2.997E+05\n\n\n3.773E+01\n\n\n1.261E+01\n\n\n\n\n\n\nEstimation de la variance\n\n\n\n\n\nEstimation 1\n\n\nEstimation 2\n\n\nEstimation 3\n\n\n\n\n1\n\n\n4.969E+06\n\n\n7.786E-02\n\n\n5.531E-05"
  },
  {
    "objectID": "presentations/var_gustave.html#variance-wrapper-et-confidentialité",
    "href": "presentations/var_gustave.html#variance-wrapper-et-confidentialité",
    "title": "Estimation de variance analytique avec gustave",
    "section": "",
    "text": "Le variance wrapper contient toute l’information nécessaire au calcul de précision : cela passe par les données de calage, les données utilisées pour certains plans de sondage, … Ces données peuvent présenter un enjeu de confidentialité en exposant ces données.\nPrenons l’exemple d’un utilisateur ne disposant que du variance wrapper precision_estim.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLorsqu’un utilisateur affiche le contenu de la fonction precision_estim, il ne voit pas les données associées.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOuf ? Pas de problème donc … ? Non, lorsqu’un utilsateur considère l’environnement associé au variance wrapper, il est possible de retrouver les données.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nOn peut, par exemple, afficher les variables de calage :\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  }
]